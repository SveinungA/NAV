# Bakgrunn og motivasjon {#bakgrunn}

Den pågående automatiseringen av beslutningsprosesser i offentlig forvaltning representerer en omveltning innenfor byråkratisk myndighetsutøvelse. 
Tilgang på store mengder relevant digital data og økende muligheter for å behandle informasjonen gjør at oppgaver som tidligere måtte behandles manuelt kan overlates til hel- eller halvautomatiserte prosesser med vesentlig redusert menneskelig inngripen [@zarsky2016trouble]. 
På den ene siden gir denne utviklingen store effektiviseringsmuligheter og potensial for offentlige besparelser [@duwe2017effects].
Den representerer også en mulighet for å utvikle bedre, evidensbaserte beslutninger, som i sin tur kan bidra til å bevare tilliten og legitimiteten til offentlig forvaltning. 
På den andre siden er nettopp ivaretakelsen av forvaltningens legitimitet i befolkningen også et risikoaspekt i denne utviklingen. 
En frykt er at feil bruk kan lede til utfall som negativt forskjellsbehandler svakerestilte grupper i samfunnet, som igjen underminerer systemtilliten.

En arbeidsgruppe oppnevnt av den tidligere amerikanske president Barack Obama publiserte rapporter hvor de uttrykte bekymring for “kode-diskriminering» i automatiserte beslutninger, hvor diskriminering av sosiale grupper oppsto som en utilsiktet følge av måten stordatateknologi er strukturert og brukes. 
Dystopiske skildringer av “svart boks”-samfunn maler et skremmende bilde av et framtidssamfunn der innbyggernes skjebner blir bestemt av skjulte, upresise, og diskriminerende automatiske beslutningsprosesser [@barocas2016big; @pasquale2015black].
I de tilfeller oppmerksomheten når ut til allmennheten, har fokus tendert å handle om hvordan beslutningene slår ulikt ut sosiale grupper. 
Det amerikanske nyhetsmagasinet ProPublica viste hvordan prediksjonsmodeller som brukes til å forutsi gjentakelsesfare for lovbrudd blant fengselsinnsatte systematisk kategoriserte svarte insatte oftere enn hvite feilaktig som personer med høy risiko for å begå en ny forbrytelse når de løslates fra fengselet (Angwin et al. 2016).

Opplevd diskriminering fra myndighetenes side mot sosiale grupperinger er ikke noe nytt, og spesielt ikke i USA hvor automatiserte beslutninger har fått mest oppmerksomhet til nå. 
I Norge har vi mindre forskjeller mellom folk, både økonomisk, politisk og sosialt. Norge har også en høyt kompetent og effektiv offentlig forvaltning som jevnt over nyter høy tillit i befolkningen.
I overgangen til økt automatisering i forvaltningen er det viktig at tilliten og legitimiteten til offentlig forvaltning opprettholdes.

NAV er ledende i utviklingen av digitale tjenester og verktøy (Hansen, Lundberg, and Syltevik 2018), og utvikler systemer som kan nyttiggjøre seg framskritt som gjøres innenfor databehandling og analyse. 
Beslutningsprosesser som benytter seg av kunstig intelligens vil være en del av løsningen for at NAV skal oppnå samfunnsoppdraget sitt om å bidra til at flere kommer i arbeid og færre på stønad, og samtidig sørge for at de som trenger det, får rett ytelse til rett tid gjennom en pålitelig og effektiv forvaltning. 
Kunstig intelligens kan brukes både i automatiserte beslutningsprosesser, og som beslutningsstøtte for saksbehandlere. 
Et sentralt kjennetegn ved kunstig intellignes er at slike systemer etterligner, erstatter og utvider menneskelig intelligent handling, og menneskelig beslutningstaking og vurdering (Mikkelsen 2019).
Mulige områder hvor kunstig intelligens kan benyttes i NAV er blant annet for å beregne sannsynlighet for at den arbeidsledige trenger bistand fra NAV; til å bestemme om en person i sykefravær skal kalles inn til oppfølgingsmøte fra NAV; og til å anbefale arbeidsrettede tiltak.
På veien mot bedre tjenester er det viktig at man har med seg brukerne – det vil si innbyggerne i Norge – og lager ansvarlige systemer som gir lik og rettferdig behandling uavhengig av sosial status.

## Rettferdige prosesser
En massiv litteratur på prosedyrerettferdighet med utspring fra sosialpsykologi (Tyler and Lind 1992) har hatt stor innvirkning på hvordan vi forstår relasjonene mellom innbyggere og myndighetene, og hvordan myndighetene bør forholde seg i møte med innbyggerne.
Når beslutningsprosessene dreier i retning av mer automatisering, fungerer denne litteraturen som et velegnet rammeverk for å undersøke empirisk om, og i så fall hvordan, relasjonene mellom innbyggerne og myndighetene vil påvirkes av denne utviklingen.
Det vi vet fra eksperimentell forskning på politisk atferd er at både aspekter ved prosessen og utfallet i seg selv påvirker rettferdighetsoppfatningen av beslutningen og i sin tur villigheten til å akseptere beslutningen (se figur under). 
På kort sikt handler det om å skaffe aksept for enkeltbeslutninger. 
I et mer overordnet perspektiv dreier det seg om systemstøtte; om å sikre tillit og legitimitet til styresmaktene, og opprettholde tilfredsheten med demokratiet som styresett. 
Legitimitet forstår vi her som makten til å få noen til villig å føye seg etter en beslutning (Weber 2009), som i sin tur gir myndighetene den autoriteten de trenger for å styre effektivt uten bruk av sanksjoner (Tyler 2006). 
Demokratisk legitimitet viser til den legitimiteten som vinnes ved at beslutningene utgår fra folkeviljen (Rosanvallon 2011).
Både tillit og legitimitet omhandler relasjonen mellom innbyggere og myndighetene, og faller under det bredere konseptet om politisk støtte (Easton 1965).

Prosessrelaterte spørsmål som undersøkes, er blant annet om rettferdighetsoppfatningen og aksepten av beslutningen påvirkes av forhold som er sentrale i demokratiske systemer.
Slike forhold kan for eksempel være grad av åpenhet rundt beslutningsprosessen (De Fine Licht et al. 2014), mulighet for direkte påvirkning på en avgjørelse (Esaiasson, Gilljam, and Persson 2012; Arnesen 2017; Christensen, Himmelroos, and Setälä 2020), hvem beslutningstakerne er, og hvor godt disse beslutningstakerne gjenspeiler befolkningen med tanke på sosial bakgrunn, også kjent som deskriptiv representasjon (Arnesen and Peters 2018; Clayton, O’Brien, and Piscopo 2019). Videre er et gjennomgående funn at dersom utfallet går imot ens egne ønsker, blir prosessen diskreditert (Esaiasson et al. 2019; Marien and Kern 2018; Arnesen, Broderstad, et al. 2019; Arnesen, Bergh, et al. 2019).

Det er viktig å studere rettferdighet fra et statsvitenskapelig perspektiv fordi oppfatninger av rettferdighet antas å påvirke institusjonell legitimitet (Tyler 2003). Dette begrenser seg ikke bare til input-siden av det politiske systemet hvor politikk vedtas, men også output-siden i forvaltningen hvor politikk settes ut i live (Krislov 2012; Rosanvallon 2011; Rothstein 2011).

Forskningen på kunstig intelligens og rettferdighet er raskt voksende. 
Flere definisjoner brukes om rettferdighet, og de fleste av dem er basert på forhold mellom sanne/falske positive og sanne/falske negativer (Verma and Rubin 2018). 
Alexandra Chouldechova @chouldechova2018case viser teoretisk og empirisk hvordan to velbrukte definisjoner av rettferdighet umulig kan oppnås samtidig i visse tilfeller. 
Hvilke definisjoner bør prioriteres når man står overfor slike avveininger? 
Chouldechovas studie viser med tydelighet at det ikke er gjort i en håndvending å lage rettferdige prediksjonsmodeller. 
Tvert imot er det komplisert utfordring som krever oppmerksomhet om konkret kontekst.
Vi vet fortsatt lite om hvilke definisjoner som resonnerer blant innbyggerne, og i hvilken grad de modereres av kontekst eller innbyggernes sosiale bakgrunn eller politiske holdninger.
Vi vet fra samfunnsforskning at hva som oppfattes som rettferdig kan variere med sosial identitet og kultur, politiske holdninger, og personlige karaktertrekk, og det er derfor viktig å gjøre konkrete empiriske studier på realistiske problemstillinger før slike prediksjonsmodeller tas i bruk. 

På tross av et økende krav om at innbyggerne må involveres og konsulteres (Balaram, Greenham, and Leonard 2018), har demokrati- og opinionsforskere i liten grad studert hvordan overgangen til økt bruk av kunstig intelligens i forvaltningen kan påvirke tillit og legitimitet. 
Viktige unntak er De Fine Licht & De Fine Licht (2020) som studerer rollen som åpenhet når det gjelder hvordan allmennheten oppfatter kunstig intelligens-beslutninger som legitim, og Binns et al (2018) som foretar eksperimentelle studier som undersøker folks oppfatning av rettferdighet i algoritmiske beslutninger.
Vår kunnskap om hvordan overgangen vil påvirke innbyggernes oppfatninger av forvaltningen er imidlertid fortsatt svært begrenset, og behovet for befolkningsrepresentative studier med et demokratiperspektiv er stort. Dette prosjektforslagets hovedmål er å bidra til å dekke dette kunnskapshullet.

```{r dag, include=FALSE}
library(ggdag)
theme_set(theme_dag())

```

Forventninger:

-	Vi antar at trekk ved beslutningsprosessene i NAV påvirker folks oppfattelse av hvor rettferdige disse prosessene er. Det er flere forhold ved prosessen som kan spille inn, og i dette prosjektet vil vi blant annet undersøke om det har noe å si hvilken informasjon beslutningsstøttesystemene baserer seg på, hvem som er involvert i utviklingen av systemene, hvordan saksbehandlerne forholder seg til anbefalingene fra systemene, hvordan beslutningene slår ut for ulike sosiale grupper informasjon som blir brukt i prediksjonsmodellen (data-input), og hvordan saksbehandler forholder seg til beslutningsstøttesystemet. Vi vil også undersøke om og i så fall hvordan innbyggerne ønsker å informeres og konsulteres ved innføring av beslutningsstøttesystemer.

- Vi stiller oss åpne for at trekk ved beslutningsprosessene kan påvirke rettferdighetsoppfattelsen ulikt, avhengig av hvilken definisjon av rettferdighet som brukes, og hvem som blir spurt.

-	Vi antar videre at hvor rettferdige beslutningsprosessene oppfattes i sin tur påvirker legitimiteten og tilliten til NAV i et lengre perspektiv.

-	Vi antar også at selve utfallet av beslutningen farger folks vurdering av hvor rettferdige prosessene er, og hvor villig de er til å akseptere utfallet.

Punktene over reflekterer våre generelle forventninger som vi ønsker å teste empirisk på konkrete områder som er direkte relevante for NAV.
Vi har i søknadsprosessen vært i dialog med relevante personer i NAV om forskningsspørsmålene, og ønsker å fortsette denne dialogen underveis i prosessen med å designe selve spørreundersøkelsen.


Vi vil gjennomføre en spørreundersøkelse på et befolkningsrepresentativt utvalg av innbyggere i Norge.
Den første delen av undersøkelsen vil ta for seg bredere spørsmål knyttet til relasjonen mellom NAV og innbyggerne slik de framstår per i dag, uavhengig av tematikken om automatisering. 
Her har vi allerede stilt noen spørsmål tidligere, slik at det blir også mulig å sammenlikne utvikling over tid. 
Vi vil også bruke bakgrunnsdata på respondentene til å analysere i hvilken grad sosiodemografisk bakgrunn henger sammen med tillit og støtte til NAV. 
Vi vil dessuten i denne delen spørre om generelle holdninger og kunnskap til automatiserte beslutninger i forvaltningen.

I den andre delen av undersøkelsen vil vi legge fram eksperimentscenarier som er eller kan bli realistiske i NAV-sammenheng. Typisk vil vi da be respondentene vurdere en situasjon hvor kunstig intelligens har blitt brukt til å bestemme et beslutningsutfall; for eksempel hvorvidt en person i sykefravær bør kalles inn til dialogmøte. Vi vil blant annet variere hvordan kunstig intelligens blir brukt med tanke på etterrettelighet, hvilke data som brukes i modellen, hvem som har utviklet modellene, samt hvor sterk innflytelse de har på den endelige beslutningen.

Eksperiment som metode i samfunnsforskningen defineres av to nøkkelelementer. 
For det første må det være en datainnsamlingsprosess som samfunnsforskeren setter i gang for å søke svar på et forskningsspørsmål.
Eksperimentdata kan ikke være observasjonsdata, altså data som allerede eksisterer i «den virkelige verden» og har skjedd – og ville ha skjedd – uten forskerens innblanding. 
Et eksperiment må også ha en kontrollgruppe som viser hvordan verdiene på den avhengige variabelen framstår når de ikke er påvirket av den eller de faktorene som undersøkes. 
Når stimulusgruppene blir introdusert for påvirkning, måler vi nivåene på disse gruppene opp mot kontrollgruppen for å se om det er noen forskjell. 
Eksperimenter i samfunnsforskningen kan gjennomføres som felteksperimenter, som lab-eksperimenter og som surveyeksperimenter.
Sistnevnte har vært mest brukt innenfor studier av demokratiske beslutningsprosesser, og er også det vi vil designe i dette prosjektet.
Eksperimenter er velegnet til å isolere enkeltfaktorers påvirkning på avhengig variabel, og bedrer muligheten for å trekke slutninger om årsakssammenhenger. 
Vi designer såkalte conjoint-eksperimenter (Hainmueller, Hopkins, and Yamamoto 2014; Green and Srinivasan 1978; Leeper, Hobolt, and Tilley 2020), som gjør oss i stand til å undersøke flere dimensjoner i ett og samme eksperiment. 
Conjoint-design kan derfor estimere effekter i en variert kontekst.

Legitimiteten til institusjoner som NAV er noe som ikke nødvendigvis endrer seg veldig fort.
Det kan derfor i en spørreundersøkelse være vanskelig å eksperimentere med faktorer som direkte påvirker legitimiteten til NAV som sådan.
Empirisk operasjonaliserer man derfor ofte legitimitet ved å spørre respondenter om de mener en beslutning bør følges, eller om de oppfatter den som akseptabel.
Det vil vi også gjøre i dette prosjektet, med antakelsen om at disse effektene vil påvirke legitimiteten til NAV i det lange løp.

Dataene vi bli samlet inn våren 2021 i runde 21 av Norsk medborgerpanels befolkningsrepresentative spørreundersøkelse. 
Medborgerpanelet er del av den samfunnsvitenskapelige infrastrukturen Digital kjernefasilitet for samfunnsvitenskapene (DIGSSCORE) ved Universitetet i Bergen. 
Panelet drives av samfunnsforskere, og er et non-profit prosjekt utelukkende benyttet til forskningsformål. 
Deltakerne representerer et tverrsnitt av den norske befolkningen, som noen ganger i året inviteres til å si sin mening i viktige spørsmål om norsk samfunn og politikk.

Det pågår for tiden et initiativ for å utvide forskningsinfrastrukturen for å legge til paneler med ansatte i forvaltningen, folkevalgte og journalister.
Dersom det oppstår en mulighet for å samle inn data på slike underutvalg i løpet av prosjektperioden, vil vi benytte oss av den.

Variabler vi kommer til å bruker i prosjektet inkluderer respondentenes alder, kjønn, utdanningsnivå, bosted, selvplassering på høyre/venstre-skalaen, deltakelse i Stortingsvalget 2017 og kommunestyrevalget 2019, partipreferanse, tillit til NAV, generell tillit til andre mennesker, tilfredshet med demokratiet, og tilfredshet med regjeringen. 
I tillegg genererer vi eksperimentvariabler som vil defineres om prosjektet starter opp.

