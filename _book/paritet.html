<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Kapittel 6 Statistisk paritet |  Demokratiske algoritmer</title>
<meta name="author" content="Mikael P. Johannesson og Sveinung Arnesen">
<meta name="description" content="Det er viktig å studere rettferdighet fra et statsvitenskapelig perspektiv fordi oppfatninger av rettferdighet antas å påvirke institusjonell legitimitet (Tyler 2003). Dette begrenser seg ikke...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Kapittel 6 Statistisk paritet |  Demokratiske algoritmer">
<meta property="og:type" content="book">
<meta property="og:description" content="Det er viktig å studere rettferdighet fra et statsvitenskapelig perspektiv fordi oppfatninger av rettferdighet antas å påvirke institusjonell legitimitet (Tyler 2003). Dette begrenser seg ikke...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kapittel 6 Statistisk paritet |  Demokratiske algoritmer">
<meta name="twitter:description" content="Det er viktig å studere rettferdighet fra et statsvitenskapelig perspektiv fordi oppfatninger av rettferdighet antas å påvirke institusjonell legitimitet (Tyler 2003). Dette begrenser seg ikke...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title=""><p><img src="norce_logo.png" style="width:1in"><br>
Demokratiske algoritmer</p></a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Innhold</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Om rapporten</a></li>
<li><a class="" href="sammendrag.html"><span class="header-section-number">2</span> Utvidet sammendrag</a></li>
<li><a class="" href="bakgrunn.html"><span class="header-section-number">3</span> Bakgrunn og motivasjon</a></li>
<li><a class="" href="oppfatninger-om-nav.html"><span class="header-section-number">4</span> Oppfatninger om NAV</a></li>
<li><a class="" href="kunstig-intelligens-i-forvaltningen.html"><span class="header-section-number">5</span> Kunstig intelligens i forvaltningen</a></li>
<li><a class="active" href="paritet.html"><span class="header-section-number">6</span> Statistisk paritet</a></li>
<li><a class="" href="input.html"><span class="header-section-number">7</span> Hvilken informasjon anses som passende?</a></li>
<li><a class="" href="representasjon.html"><span class="header-section-number">8</span> Representativt byråkrati</a></li>
<li><a class="" href="diskusjon.html"><span class="header-section-number">9</span> Diskusjon</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="paritet" class="section level1" number="6">
<h1>
<span class="header-section-number">Kapittel 6</span> Statistisk paritet<a class="anchor" aria-label="anchor" href="#paritet"><i class="fas fa-link"></i></a>
</h1>
<p>Det er viktig å studere rettferdighet fra et statsvitenskapelig perspektiv fordi oppfatninger av rettferdighet antas å påvirke institusjonell legitimitet <span class="citation">(<a href="references.html#ref-tyler2003procedural" role="doc-biblioref">Tyler 2003</a>)</span>.
Dette begrenser seg ikke bare til input-siden av det politiske systemet hvor politikk vedtas, men også output-siden i forvaltningen hvor politikk settes ut i live <span class="citation">(<a href="references.html#ref-krislov2012representative" role="doc-biblioref">Krislov 2012</a>; <a href="references.html#ref-rosanvallon2011democratic" role="doc-biblioref">Rosanvallon 2011</a>; <a href="references.html#ref-rothstein2009creating" role="doc-biblioref">Rothstein 2009</a>)</span>.</p>
<p>Flere definisjoner brukes om rettferdighet, og de fleste av dem er basert på forhold mellom sanne/falske positive og sanne/falske negativer <span class="citation">(<a href="references.html#ref-verma2018fairness" role="doc-biblioref">Verma and Rubin 2018</a>)</span>.
Alexandra Chouldechova <span class="citation">(<a href="references.html#ref-chouldechova2018case" role="doc-biblioref">2018</a>)</span> viser teoretisk og empirisk hvordan to velbrukte definisjoner av rettferdighet umulig kan oppnås samtidig i visse tilfeller.
Hvilke definisjoner bør prioriteres når man står overfor slike avveininger?
Chouldechovas studie viser med tydelighet at det ikke er gjort i en håndvending å lage rettferdige prediksjonsmodeller.
Tvert imot er det komplisert utfordring som krever oppmerksomhet om konkret kontekst.
Vi vet fortsatt lite om hvilke definisjoner som resonnerer blant innbyggerne, og i hvilken grad de modereres av kontekst eller innbyggernes sosiale bakgrunn eller politiske holdninger.
Vi vet fra samfunnsforskning at hva som oppfattes som rettferdig kan variere med sosial identitet og kultur, politiske holdninger, og personlige karaktertrekk, og det er derfor viktig å gjøre konkrete empiriske studier.
I dette kapitlet tar vi derfor for oss et realistisk scenario for NAV hvor vi setter opp to motstridende rettferdighetshensyn knyttet til hvilke sykmeldte NAV skal tilby dialogmøte.</p>
<p>Et dialogmøte er en samtale mellom NAV og den sykmeldte som anses som positivt for den sykmeldtes muligheter for å komme tilbake i arbeid.
I prinsippet har alle rett på et dialogmøte, men i praksis foregår det en siling hvor det gjøres en vurdering av hvem som har mest nytte av et slikt møte.
Bruk av maskinlæring og kunstig intelligens kan i dette tilfellet bidra til bedre estimater for hvem som er i fare for å bli langtidssykemeldt, og derfor kan ha større nytte av et dialogmøte.
Derfor er NAV i innledende stadier på å utvikle maskinlæringsmodeller som predikerer sannsynlighet for at en sykemeldt fortsatt vil være sykemeldt 12 uker fram i tid.</p>
<p>Når man bestemmer innretningen på en modell må man foreta prioriteringer.
En prinsipielt viktig prioritering handler om man skal ta i bruk såkalt statistisk paritet som rettferdighetsprinsipp på utvalgte egenskaper ved individene det gjelder.
Kjønnsparitet er ett eksempel, men det kan også handle om statistisk paritet etter alder, etnisitet, geografi, med mer.
Et kjent eksempel innenfor litteraturen om rettferdig bruk av kunstig intelligens er studien som viser hvordan afro-amerikanske fengselsinnsatte sjeldnere blir tilbudt prøveløslatelse enn hva andelen deres skulle tilsi.
Dette skjer når avgjørelsen om prøveløslatelse baserer seg på prediksjonsmodeller om risikoen for at den innsatte blir tatt påny for en kriminell handling dersom hen slippes fri <span class="citation">(<a href="references.html#ref-chouldechova2017fair" role="doc-biblioref">Chouldechova 2017</a>)</span>.
Å anvende paritetsprinsippet her innebærer å sikre at andelen innsatte som tilbys prøveløslatelse samsvarer med andelen innsatte for hver av de etniske gruppene i fengselet.
Fordelen med å bruke statistisk paritet etter etnisitet er at prøveløslatelse blir likt fordelt blant de etniske gruppene, og slik sett kan oppleves som rettferdig fordelt.
Utfordringen ved å bruke dette prinsippet er at andre egenskaper ved de innsatte – som for eksempel risikovurderinger om tilbakefall til kriminelle handlinger – blir nedprioritert.
Er etnisitet i dette tilfellet så viktig at man bør la det gå på bekostning av risikovurderinger knyttet til tilbakefall?</p>
<p>NAVs tilfelle om dialogmøte er mindre dramatisk enn eksempelet om prøveløslatelse.
Samtidig er de prinsipielle problemstillingene de samme.
Statistisk paritet innebærer i tilfellet om dialogmøte at modellen sikrer at like mange menn og kvinner skal få tilbud om dialogmøte.
Denne prioriteringer vil i så fall gå delvis på bekostning av å prioritere treffsikkerhet med tanke på å invitere de som har størst nytte av et slikt møte.</p>
<p>For å studere respondentenes umiddelbare reaksjoner til et slik etisk dilemma knyttet til rettferdig bruk av kunstig intelligens ber vi respondentene se for seg et valg mellom to alternative maskinlæringsmodeller for å velge hvem som skal få tilbud om dialogmøte.</p>
<p>Ingen av modellene er perfekte, men de feiler på ulike måter.</p>
<p>Den første modellen er mest <em>treffsikker</em>.
Det vil si at det totalt sett er flere sykemeldte med behov for dialogmøte som får tilbudet enn tilfellet er for den andre modellen.
Samtidig har modellen en bias til fordel for menn, som gjør at det er flere kvinner med behov for dialogmøte som ikke får tilbudet.
Andelen som har behov for dialogmøte <em>uten å få tilbud</em> er altså større hos kvinner enn menn.</p>
<p>Den andre modellen sikrer statistisk paritet etter kjønn, nemlig at andelen av de sykmeldte som kalles inn til dialogmøte er like stor henholdsvis for kvinner som for menn.
Imidlertid er den mindre treffsikker totalt sett, slik at færre som har behov for dialogmøte blir innkalt.
Dette gjelder både kvinner og menn.</p>
<p>Hvis det står mellom disse to modellene, hvilken modell synes respondentene virker mest rettferdig?
Figuren under viser at et knapt flertall foretrekker en modell som vektlegger statistisk paritet.
Det vil si at de ønsker å bruke en modell som sikrer likebehandling av kjønn, selv på bekostning av lavere treffsikkerhet totalt sett.</p>
<div class="inline-figure"><img src="figs/png/fig_parity_avg.png"></div>
<p>I teksten over står det at den mest treffsikre modellen favoriserte menn.
For å undersøke om det har noen innvirkning på svarene hvilket kjønn modellen favoriserer veksler vi på denne beskrivelsen.
Halvparten av respondentene får vite at modellen har en bias til fordel for menn, mens den andre halvparten av respondentene får vite at modellen favoriserer kvinner.
Spiller det noen rolle hvilket kjønn modellen favoriserer?
Resultatene viser at det gjør det.</p>
<p>I figuren under ser vi at det er i de tilfeller hvor menn blir fordelaktig behandlet ved bruk av den mest treffsikre modellen at flertallet ønsker å bruke en modell som sikrer likebehandling av kjønn.
Det er en signifikant større andel av respondentene som foretrekker paritetsprinsippet når menn har fordel av den treffsikre modellen enn når kvinner har det.</p>
<p>Hva dette skyldes vet vi ikke.
Man ser liknende kjønnseffekter i eksperimenter om politisk representasjon, hvor kvinnelige kandidater jevnt over foretrekkes i noe høyere grad enn mannlige kandidater gjør <span class="citation">(<a href="references.html#ref-schwarz2018have" role="doc-biblioref">Schwarz and Coppock 2018</a>)</span>.
I den litteraturen pekes det på forklaringer om at folk er motivert ut fra et ønske om å kompensere for historisk underrepresentasjon av kvinner i politiske stillinger.
Hvorvidt det ligger liknende strukturelle motivasjoner for våre resultater, psykologiske faktorer, eller andre forhold er et interessant forskningsspørsmål som vi ikke har data til å besvare, og som derfor bør studeres videre.</p>
<div class="inline-figure"><img src="figs/png/fig_parity_treat_avg.png"></div>
<p>Det vi imidlertid ser, og til forskjell fra litteraturen om politisk representasjon, er at kvinner responderer noe mer på informasjon om hvilket kjønn som kommer best ut av en modell som prioriterer treffsikkerhet.
Både menn og kvinner foretrekker paritetsmodellen oftere i de tilfellene kvinnene kommer dårlig ut av treffsikkerhetsmodellen enn i de tilfellene hvor menn kommer dårlig ut av samme modell, men denne effekten er noe sterkere hos kvinner enn menn.</p>
<p>Det er også en generell forskjell blant respondentene i den forstand at kvinner i sterkere grad foretrekker paritetsmodellen enn menn gjør, uavhengig av om det er menn eller kvinner som kommer best ut av det.</p>
<div class="inline-figure">
<img src="figs/png/fig_parity_treat_avg_by_gender.png"><!-- Vi observerer også en modererende effekt av kunnskap om maskinlæring: --><!-- Jevnt over ser vi at jo høyere kunnskap om maskinlæring, desto høyere andel modellen som prioriterer treffsikkerhet framfor statistisk paritet.  --><!-- Det her er igjen verdt å nevne at slike bivariate, statistiske sammehenger ikke sier noe om årsakssammenhenger. --><!-- SKAL VI TA MED DENNE FIGUREN? DEN PASSER IKKE SUPERGODT INN I NARRATIVET, OG ER VANSKELIG Å DISKUTERE. --><!-- ![](figs/png/fig_parity_treat_avg_by_ml_know.png) -->
</div>

</div>
  <div class="chapter-nav">
<div class="prev"><a href="kunstig-intelligens-i-forvaltningen.html"><span class="header-section-number">5</span> Kunstig intelligens i forvaltningen</a></div>
<div class="next"><a href="input.html"><span class="header-section-number">7</span> Hvilken informasjon anses som passende?</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>På denne siden</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#paritet"><span class="header-section-number">6</span> Statistisk paritet</a></li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong><p><img src="norce_logo.png" style="width:1in"><br>
Demokratiske algoritmer</p></strong>" er skrevet av Mikael P. Johannesson og Sveinung Arnesen. Dato: 2022-03-07.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Laget med R-pakken <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer>
</body>
</html>
