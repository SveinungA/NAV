<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Bakgrunn og motivasjon | Demokratiske algoritmer</title>
  <meta name="description" content="Hvordan oppnå legitimitet og rettferdighet i automatiserte beslutningsprosesser i offentlig forvaltning" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Bakgrunn og motivasjon | Demokratiske algoritmer" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Hvordan oppnå legitimitet og rettferdighet i automatiserte beslutningsprosesser i offentlig forvaltning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Bakgrunn og motivasjon | Demokratiske algoritmer" />
  
  <meta name="twitter:description" content="Hvordan oppnå legitimitet og rettferdighet i automatiserte beslutningsprosesser i offentlig forvaltning" />
  



<meta name="date" content="2022-02-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="oppfatninger-om-nav.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Demokratiske algoritmer</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Om rapporten</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#kort-sammendrag"><i class="fa fa-check"></i><b>1.1</b> Kort sammendrag</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#forfattere"><i class="fa fa-check"></i><b>1.2</b> Forfattere</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#referansegruppe"><i class="fa fa-check"></i><b>1.3</b> Referansegruppe</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#data"><i class="fa fa-check"></i><b>1.4</b> Data</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#finansiering"><i class="fa fa-check"></i><b>1.5</b> Finansiering</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bakgrunn.html"><a href="bakgrunn.html"><i class="fa fa-check"></i><b>2</b> Bakgrunn og motivasjon</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bakgrunn.html"><a href="bakgrunn.html#byråkratisk-omveltning"><i class="fa fa-check"></i><b>2.1</b> Byråkratisk omveltning</a></li>
<li class="chapter" data-level="2.2" data-path="bakgrunn.html"><a href="bakgrunn.html#rettferdighet-og-legitimitet"><i class="fa fa-check"></i><b>2.2</b> Rettferdighet og legitimitet</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html"><i class="fa fa-check"></i><b>3</b> Oppfatninger om NAV</a>
<ul>
<li class="chapter" data-level="3.1" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html#erfaring-med-og-kjennskap-til-nav"><i class="fa fa-check"></i><b>3.1</b> Erfaring med og kjennskap til NAV</a></li>
<li class="chapter" data-level="3.2" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html#tillit"><i class="fa fa-check"></i><b>3.2</b> Tillit</a></li>
<li class="chapter" data-level="3.3" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html#byråkratisk-kompetanse"><i class="fa fa-check"></i><b>3.3</b> Byråkratisk kompetanse</a></li>
<li class="chapter" data-level="3.4" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html#tiltro-til-likebehandling-i-nav"><i class="fa fa-check"></i><b>3.4</b> Tiltro til likebehandling i NAV</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="kunstig-intelligens-i-forvaltningen.html"><a href="kunstig-intelligens-i-forvaltningen.html"><i class="fa fa-check"></i><b>4</b> Kunstig intelligens i forvaltningen</a>
<ul>
<li class="chapter" data-level="4.1" data-path="kunstig-intelligens-i-forvaltningen.html"><a href="kunstig-intelligens-i-forvaltningen.html#norske-innbyggeres-kjennskap-og-følelser-knyttet-til-maskinlæring-og-kunstig-intelligens"><i class="fa fa-check"></i><b>4.1</b> Norske innbyggeres kjennskap og følelser knyttet til maskinlæring og kunstig intelligens</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="kunstig-intelligens-i-forvaltningen.html"><a href="kunstig-intelligens-i-forvaltningen.html#interesser-ivaretatt-med-maskinlæring"><i class="fa fa-check"></i><b>4.1.1</b> Interesser ivaretatt med maskinlæring?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="kunstig-intelligens-i-forvaltningen.html"><a href="kunstig-intelligens-i-forvaltningen.html#bruke-kunstig-intelligens"><i class="fa fa-check"></i><b>4.2</b> Bruke kunstig intelligens?</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="paritet.html"><a href="paritet.html"><i class="fa fa-check"></i><b>5</b> Statistisk paritet</a></li>
<li class="chapter" data-level="6" data-path="input.html"><a href="input.html"><i class="fa fa-check"></i><b>6</b> Inputvariabler</a></li>
<li class="chapter" data-level="7" data-path="representasjon.html"><a href="representasjon.html"><i class="fa fa-check"></i><b>7</b> Representativt byråkrati</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/SveinungA/NAV" target="blank">GitHub-depot</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Demokratiske algoritmer</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bakgrunn" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Bakgrunn og motivasjon</h1>
<div id="byråkratisk-omveltning" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Byråkratisk omveltning</h2>
<p>Den pågående automatiseringen av beslutningsprosesser i offentlig forvaltning representerer en omveltning innenfor byråkratisk myndighetsutøvelse.
Tilgang på store mengder relevant digital data og økende muligheter for å behandle informasjonen gjør at oppgaver som tidligere måtte behandles manuelt kan overlates til hel- eller halvautomatiserte prosesser med vesentlig redusert menneskelig inngripen <span class="citation">(<a href="#ref-zarsky2016trouble" role="doc-biblioref">Zarsky 2016</a>)</span>.
På den ene siden gir denne utviklingen store effektiviseringsmuligheter og potensial for offentlige besparelser <span class="citation">(<a href="#ref-duwe2017effects" role="doc-biblioref"><strong>duwe2017effects?</strong></a>)</span>.
Den representerer også en mulighet for å utvikle bedre, evidensbaserte beslutninger, som i sin tur kan bidra til å bevare tilliten og legitimiteten til offentlig forvaltning.
På den andre siden er nettopp ivaretakelsen av forvaltningens legitimitet i befolkningen også et risikoaspekt i denne utviklingen.
En frykt er at feil bruk kan lede til utfall som negativt forskjellsbehandler svakerestilte grupper i samfunnet, som igjen underminerer systemtilliten.</p>
<p>En arbeidsgruppe oppnevnt av den tidligere amerikanske president Barack Obama publiserte rapporter hvor de uttrykte bekymring for “kode-diskriminering» i automatiserte beslutninger, hvor diskriminering av sosiale grupper oppsto som en utilsiktet følge av måten stordatateknologi er strukturert og brukes.
Dystopiske skildringer av “svart boks”-samfunn maler et skremmende bilde av et framtidssamfunn der innbyggernes skjebner blir bestemt av skjulte, upresise, og diskriminerende automatiske beslutningsprosesser <span class="citation">(<a href="#ref-barocas2016big" role="doc-biblioref">Barocas and Selbst 2016</a>; <a href="#ref-pasquale2015black" role="doc-biblioref">Pasquale 2015</a>)</span>.
I de tilfeller oppmerksomheten når ut til allmennheten, har fokus tendert å handle om hvordan beslutningene slår ulikt ut sosiale grupper.
Det amerikanske nyhetsmagasinet ProPublica viste hvordan prediksjonsmodeller som brukes til å forutsi gjentakelsesfare for lovbrudd blant fengselsinnsatte systematisk kategoriserte svarte insatte oftere enn hvite feilaktig som personer med høy risiko for å begå en ny forbrytelse når de løslates fra fengselet (Angwin et al. 2016).</p>
<p>Opplevd diskriminering fra myndighetenes side mot sosiale grupperinger er ikke noe nytt, og spesielt ikke i USA hvor automatiserte beslutninger har fått mest oppmerksomhet til nå.
I Norge har vi mindre forskjeller mellom folk, både økonomisk, politisk og sosialt. Norge har også en høyt kompetent og effektiv offentlig forvaltning som jevnt over nyter høy tillit i befolkningen.
I overgangen til økt automatisering i forvaltningen er det viktig at tilliten og legitimiteten til offentlig forvaltning opprettholdes.</p>
<p>NAV er ledende i utviklingen av digitale tjenester og verktøy (Hansen, Lundberg, and Syltevik 2018), og utvikler systemer som kan nyttiggjøre seg framskritt som gjøres innenfor databehandling og analyse.
Beslutningsprosesser som benytter seg av kunstig intelligens vil være en del av løsningen for at NAV skal oppnå samfunnsoppdraget sitt om å bidra til at flere kommer i arbeid og færre på stønad, og samtidig sørge for at de som trenger det, får rett ytelse til rett tid gjennom en pålitelig og effektiv forvaltning.
Kunstig intelligens kan brukes både i automatiserte beslutningsprosesser, og som beslutningsstøtte for saksbehandlere.
Et sentralt kjennetegn ved kunstig intellignes er at slike systemer etterligner, erstatter og utvider menneskelig intelligent handling, og menneskelig beslutningstaking og vurdering (Mikkelsen 2019).
Mulige områder hvor kunstig intelligens kan benyttes i NAV er blant annet for å beregne sannsynlighet for at den arbeidsledige trenger bistand fra NAV; til å bestemme om en person i sykefravær skal kalles inn til oppfølgingsmøte fra NAV; og til å anbefale arbeidsrettede tiltak.
På veien mot bedre tjenester er det viktig at man har med seg brukerne – det vil si innbyggerne i Norge – og lager ansvarlige systemer som gir lik og rettferdig behandling uavhengig av sosial status.</p>
</div>
<div id="rettferdighet-og-legitimitet" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Rettferdighet og legitimitet</h2>
<p>En massiv litteratur på prosedyrerettferdighet med utspring fra sosialpsykologi (Tyler and Lind 1992) har hatt stor innvirkning på hvordan vi forstår relasjonene mellom innbyggere og myndighetene, og hvordan myndighetene bør forholde seg i møte med innbyggerne.
Når beslutningsprosessene dreier i retning av mer automatisering, fungerer denne litteraturen som et velegnet rammeverk for å undersøke empirisk om, og i så fall hvordan, relasjonene mellom innbyggerne og myndighetene vil påvirkes av denne utviklingen.
Det vi vet fra eksperimentell forskning på politisk atferd er at både aspekter ved prosessen og utfallet i seg selv påvirker rettferdighetsoppfatningen av beslutningen og i sin tur villigheten til å akseptere beslutningen (se figur under).
På kort sikt handler det om å skaffe aksept for enkeltbeslutninger.
I et mer overordnet perspektiv dreier det seg om systemstøtte; om å sikre tillit og legitimitet til styresmaktene, og opprettholde tilfredsheten med demokratiet som styresett.
Legitimitet forstår vi her som makten til å få noen til villig å føye seg etter en beslutning (Weber 2009), som i sin tur gir myndighetene den autoriteten de trenger for å styre effektivt uten bruk av sanksjoner (Tyler 2006).
Demokratisk legitimitet viser til den legitimiteten som vinnes ved at beslutningene utgår fra folkeviljen (Rosanvallon 2011).
Både tillit og legitimitet omhandler relasjonen mellom innbyggere og myndighetene, og faller under det bredere konseptet om politisk støtte (Easton 1965).</p>
<p>Prosessrelaterte spørsmål som har blitt studert er blant annet om rettferdighetsoppfatningen og aksepten av beslutningen påvirkes av forhold som er sentrale i demokratiske systemer.
Slike forhold kan for eksempel være grad av åpenhet rundt beslutningsprosessen (De Fine Licht et al. 2014), mulighet for direkte påvirkning på en avgjørelse (Esaiasson, Gilljam, and Persson 2012; Arnesen 2017; Christensen, Himmelroos, and Setälä 2020), hvem beslutningstakerne er, og hvor godt disse beslutningstakerne gjenspeiler befolkningen med tanke på sosial bakgrunn, også kjent som deskriptiv representasjon (Arnesen and Peters 2018; Clayton, O’Brien, and Piscopo 2019). Videre er et gjennomgående funn at dersom utfallet går imot ens egne ønsker, blir prosessen diskreditert (Esaiasson et al. 2019; Marien and Kern 2018; Arnesen, Broderstad, et al. 2019; Arnesen, Bergh, et al. 2019).</p>
<p>Det er viktig å studere rettferdighet fra et statsvitenskapelig perspektiv fordi oppfatninger av rettferdighet antas å påvirke institusjonell legitimitet (Tyler 2003). Dette begrenser seg ikke bare til input-siden av det politiske systemet hvor politikk vedtas, men også output-siden i forvaltningen hvor politikk settes ut i live (Krislov 2012; Rosanvallon 2011; Rothstein 2011).</p>
<p><img src="NAV_files/figure-html/dag-1.png" width="1440" /></p>
<p>Forskningen på kunstig intelligens og rettferdighet er raskt voksende.
Flere definisjoner brukes om rettferdighet, og de fleste av dem er basert på forhold mellom sanne/falske positive og sanne/falske negativer (Verma and Rubin 2018).
Alexandra Chouldechova <span class="citation"><a href="#ref-chouldechova2018case" role="doc-biblioref">Chouldechova et al.</a> (<a href="#ref-chouldechova2018case" role="doc-biblioref">2018</a>)</span> viser teoretisk og empirisk hvordan to velbrukte definisjoner av rettferdighet umulig kan oppnås samtidig i visse tilfeller.
Hvilke definisjoner bør prioriteres når man står overfor slike avveininger?
Chouldechovas studie viser med tydelighet at det ikke er gjort i en håndvending å lage rettferdige prediksjonsmodeller.
Tvert imot er det komplisert utfordring som krever oppmerksomhet om konkret kontekst.
Vi vet fortsatt lite om hvilke definisjoner som resonnerer blant innbyggerne, og i hvilken grad de modereres av kontekst eller innbyggernes sosiale bakgrunn eller politiske holdninger.
Vi vet fra samfunnsforskning at hva som oppfattes som rettferdig kan variere med sosial identitet og kultur, politiske holdninger, og personlige karaktertrekk, og det er derfor viktig å gjøre konkrete empiriske studier på realistiske problemstillinger før slike prediksjonsmodeller tas i bruk.
I [kapittel] @ref(#paritet) tar vi for oss et realistisk scenario for NAV hvor vi setter opp to motstridende rettferdighetshensyn knyttet til hvem som skal få tilbud om dialogmøte.</p>
<p>På tross av et økende krav om at innbyggerne må involveres og konsulteres (Balaram, Greenham, and Leonard 2018), har demokrati- og opinionsforskere i liten grad studert hvordan overgangen til økt bruk av kunstig intelligens i forvaltningen kan påvirke tillit og legitimitet.
Viktige unntak er De Fine Licht &amp; De Fine Licht (2020) som studerer rollen som åpenhet når det gjelder hvordan allmennheten oppfatter kunstig intelligens-beslutninger som legitim, og Binns et al (2018) som foretar eksperimentelle studier som undersøker folks oppfatning av rettferdighet i algoritmiske beslutninger.
Vår kunnskap om hvordan overgangen vil påvirke innbyggernes oppfatninger av forvaltningen er imidlertid fortsatt svært begrenset, og behovet for befolkningsrepresentative studier med et demokratiperspektiv er stort.
Det er motivasjonen for å lage denne rapporten.</p>
<p>Rapporten presenterer resultatene fra en spørreundersøkelse gjennomført på et befolkningsrepresentativt utvalg av innbyggere i Norge.
Undersøkelsen tar for seg generelle holdninger til og kunnskap om maskinlæring og kunstig intelligens i befolkningen.
Bredere spørsmål knyttet til relasjonen mellom NAV og innbyggerne – uavhengig av tematikken om maskinlæring og kunstig intelligens – blir også analysert for å kontekstualisere de mer spesifikke spørsmålene og eksperimentene knyttet til bruk av maskinlæring og kunstig intelligens i NAV.
Deretter fokuserer vi på holdninger som har relevans for en framtid hvor maskinlæring og kunstig intelligens har en sentral rolle i.
Dette gjelder problemstillinger knyttet til konkrete, aktuelle situasjoner i NAV, såvel som mer overordnete spørsmål om maskinlæring og kunstig intelligens i forvaltningen.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-barocas2016big" class="csl-entry">
Barocas, Solon, and Andrew D Selbst. 2016. <span>“Big Data’s Disparate Impact.”</span>
</div>
<div id="ref-chouldechova2018case" class="csl-entry">
Chouldechova, Alexandra, Diana Benavides-Prado, Oleksandr Fialko, and Rhema Vaithianathan. 2018. <span>“A Case Study of Algorithm-Assisted Decision Making in Child Maltreatment Hotline Screening Decisions.”</span> In <em>Conference on Fairness, Accountability and Transparency</em>, 134–48.
</div>
<div id="ref-pasquale2015black" class="csl-entry">
Pasquale, Frank. 2015. <em>The Black Box Society: The Secret Algorithms That Control Money and Information</em>. Harvard University Press.
</div>
<div id="ref-zarsky2016trouble" class="csl-entry">
Zarsky, Tal. 2016. <span>“The Trouble with Algorithmic Decisions: An Analytic Road Map to Examine Efficiency and Fairness in Automated and Opaque Decision Making.”</span> <em>Science, Technology, &amp; Human Values</em> 41 (1): 118–32.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="oppfatninger-om-nav.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["NAV.pdf", "NAV.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
