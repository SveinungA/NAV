<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Kapittel 3 Bakgrunn og motivasjon |  Demokratiske algoritmer</title>
  <meta name="description" content="Demokratiske algoritmer: Hvordan oppnå legitimitet og rettferdighet i automatiserte beslutningsprosesser i offentlig forvaltning" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Kapittel 3 Bakgrunn og motivasjon |  Demokratiske algoritmer" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Demokratiske algoritmer: Hvordan oppnå legitimitet og rettferdighet i automatiserte beslutningsprosesser i offentlig forvaltning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Kapittel 3 Bakgrunn og motivasjon |  Demokratiske algoritmer" />
  
  <meta name="twitter:description" content="Demokratiske algoritmer: Hvordan oppnå legitimitet og rettferdighet i automatiserte beslutningsprosesser i offentlig forvaltning" />
  

<meta name="author" content="Mikael P. Johannesson og Sveinung Arnesen" />


<meta name="date" content="2022-03-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sammendrag.html"/>
<link rel="next" href="oppfatninger-om-nav.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Demokratiske algoritmer</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Om rapporten</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#forfattere"><i class="fa fa-check"></i><b>1.1</b> Forfattere</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#referansegruppe"><i class="fa fa-check"></i><b>1.2</b> Referansegruppe</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#data"><i class="fa fa-check"></i><b>1.3</b> Data</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#finansiering"><i class="fa fa-check"></i><b>1.4</b> Finansiering</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#sitering"><i class="fa fa-check"></i><b>1.5</b> Sitering</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sammendrag.html"><a href="sammendrag.html"><i class="fa fa-check"></i><b>2</b> Utvidet sammendrag</a></li>
<li class="chapter" data-level="3" data-path="bakgrunn.html"><a href="bakgrunn.html"><i class="fa fa-check"></i><b>3</b> Bakgrunn og motivasjon</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bakgrunn.html"><a href="bakgrunn.html#byråkratisk-omveltning"><i class="fa fa-check"></i><b>3.1</b> Byråkratisk omveltning</a></li>
<li class="chapter" data-level="3.2" data-path="bakgrunn.html"><a href="bakgrunn.html#beslutningsprosesser-rettferdighet-og-legitimitet"><i class="fa fa-check"></i><b>3.2</b> Beslutningsprosesser, rettferdighet og legitimitet</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html"><i class="fa fa-check"></i><b>4</b> Oppfatninger om NAV</a>
<ul>
<li class="chapter" data-level="4.1" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html#erfaring-med-og-kjennskap-til-nav"><i class="fa fa-check"></i><b>4.1</b> Erfaring med og kjennskap til NAV</a></li>
<li class="chapter" data-level="4.2" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html#tillit"><i class="fa fa-check"></i><b>4.2</b> Tillit</a></li>
<li class="chapter" data-level="4.3" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html#byråkratisk-kompetanse"><i class="fa fa-check"></i><b>4.3</b> Byråkratisk kompetanse</a></li>
<li class="chapter" data-level="4.4" data-path="oppfatninger-om-nav.html"><a href="oppfatninger-om-nav.html#tiltro-til-likebehandling-i-nav"><i class="fa fa-check"></i><b>4.4</b> Tiltro til likebehandling i NAV</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="kunstig-intelligens-i-forvaltningen.html"><a href="kunstig-intelligens-i-forvaltningen.html"><i class="fa fa-check"></i><b>5</b> Kunstig intelligens i forvaltningen</a>
<ul>
<li class="chapter" data-level="5.1" data-path="kunstig-intelligens-i-forvaltningen.html"><a href="kunstig-intelligens-i-forvaltningen.html#norske-innbyggeres-kjennskap-og-følelser-knyttet-til-maskinlæring-og-kunstig-intelligens"><i class="fa fa-check"></i><b>5.1</b> Norske innbyggeres kjennskap og følelser knyttet til maskinlæring og kunstig intelligens</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="kunstig-intelligens-i-forvaltningen.html"><a href="kunstig-intelligens-i-forvaltningen.html#interesser-ivaretatt-med-maskinlæring"><i class="fa fa-check"></i><b>5.1.1</b> Interesser ivaretatt med maskinlæring?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="kunstig-intelligens-i-forvaltningen.html"><a href="kunstig-intelligens-i-forvaltningen.html#bruke-kunstig-intelligens"><i class="fa fa-check"></i><b>5.2</b> Bruke kunstig intelligens?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="paritet.html"><a href="paritet.html"><i class="fa fa-check"></i><b>6</b> Statistisk paritet</a></li>
<li class="chapter" data-level="7" data-path="input.html"><a href="input.html"><i class="fa fa-check"></i><b>7</b> Hvilken informasjon anses som passende?</a></li>
<li class="chapter" data-level="8" data-path="representasjon.html"><a href="representasjon.html"><i class="fa fa-check"></i><b>8</b> Representativt byråkrati</a></li>
<li class="chapter" data-level="9" data-path="diskusjon.html"><a href="diskusjon.html"><i class="fa fa-check"></i><b>9</b> Diskusjon</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/SveinungA/NAV" target="blank">GitHub-depot</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><p><img src="norce_logo.png" style="width:1in" /><br />
Demokratiske algoritmer</p></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bakgrunn" class="section level1" number="3">
<h1><span class="header-section-number">Kapittel 3</span> Bakgrunn og motivasjon</h1>
<div id="byråkratisk-omveltning" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Byråkratisk omveltning</h2>
<p>Den pågående automatiseringen av beslutningsprosesser i offentlig forvaltning representerer en omveltning innenfor byråkratisk myndighetsutøvelse.
Tilgang på store mengder relevant digital data og økende muligheter for å behandle informasjonen gjør at oppgaver som tidligere måtte behandles manuelt kan overlates til hel- eller halvautomatiserte prosesser med vesentlig redusert menneskelig inngripen <span class="citation">(<a href="#ref-zarsky2016trouble" role="doc-biblioref">Zarsky 2016</a>)</span>.
På den ene siden gir denne utviklingen store effektiviseringsmuligheter og potensial for offentlige besparelser <span class="citation">(<a href="#ref-duwe2017effects" role="doc-biblioref">Duwe and Rocque 2017</a>)</span>.
Den representerer også en mulighet for å utvikle bedre, evidensbaserte beslutninger, som i sin tur kan bidra til å bevare tilliten og legitimiteten til offentlig forvaltning.
På den andre siden er nettopp ivaretakelsen av forvaltningens legitimitet i befolkningen også et risikoaspekt i denne utviklingen.
En frykt er at feil bruk kan lede til utfall som negativt forskjellsbehandler svakerestilte grupper i samfunnet, som igjen underminerer systemtilliten.</p>
<p>En arbeidsgruppe oppnevnt av den tidligere amerikanske president Barack Obama publiserte rapporter hvor de uttrykte bekymring for “kode-diskriminering» i automatiserte beslutninger, hvor diskriminering av sosiale grupper oppsto som en utilsiktet følge av måten stordatateknologi er strukturert og brukes.
Dystopiske skildringer av “svart boks”-samfunn maler et skremmende bilde av et framtidssamfunn der innbyggernes skjebner blir bestemt av skjulte, upresise, og diskriminerende automatiske beslutningsprosesser <span class="citation">(<a href="#ref-barocas2016big" role="doc-biblioref">Barocas and Selbst 2016</a>; <a href="#ref-pasquale2015black" role="doc-biblioref">Pasquale 2015</a>)</span>.
I de tilfeller oppmerksomheten når ut til allmennheten, har fokus tendert å handle om hvordan beslutningene slår ulikt ut sosiale grupper.
Det amerikanske nyhetsmagasinet ProPublica viste hvordan prediksjonsmodeller som brukes til å forutsi gjentakelsesfare for lovbrudd blant fengselsinnsatte systematisk kategoriserte svarte insatte oftere enn hvite feilaktig som personer med høy risiko for å begå en ny forbrytelse når de løslates fra fengselet <span class="citation">(<a href="#ref-angwin2016machine" role="doc-biblioref">Angwin et al. 2016</a>)</span>.</p>
<p>Opplevd diskriminering fra myndighetenes side mot sosiale grupperinger er ikke noe nytt, og spesielt ikke i USA hvor automatiserte beslutninger har fått mest oppmerksomhet til nå.
I Norge har vi mindre forskjeller mellom folk, både økonomisk, politisk og sosialt.
Norge har også en høyt kompetent og effektiv offentlig forvaltning som jevnt over nyter høy tillit i befolkningen.
I overgangen til økt automatisering i forvaltningen er det viktig at tilliten og legitimiteten til offentlig forvaltning opprettholdes.</p>
<p>NAV er ledende i utviklingen av digitale tjenester og verktøy<span class="citation">(<a href="#ref-hansen2018digitalization" role="doc-biblioref">Hansen, Lundberg, and Syltevik 2018</a>)</span>, og utvikler systemer som kan nyttiggjøre seg framskritt som gjøres innenfor databehandling og analyse.
Beslutningsprosesser som benytter seg av maskinlæring og kunstig intelligens vil være en del av løsningen for at NAV skal oppnå samfunnsoppdraget sitt om å bidra til at flere kommer i arbeid og færre på stønad, og samtidig sørge for at de som trenger det, får rett ytelse til rett tid gjennom en pålitelig og effektiv forvaltning.
Maskinlæring og kunstig intelligens kan brukes både i helautomatiserte beslutningsprosesser, og som beslutningsstøtte for saksbehandlere.
Et sentralt kjennetegn er at slike verktøy etterligner, erstatter og utvider menneskelig intelligent handling, og menneskelig beslutningstaking og vurdering.
Mulige områder hvor maskinlæring og kunstig intelligens kan benyttes i NAV er blant annet for å beregne sannsynlighet for at den arbeidsledige trenger bistand fra NAV; til å bestemme om en person i sykefravær skal kalles inn til oppfølgingsmøte fra NAV; og til å anbefale arbeidsrettede tiltak.
På veien mot bedre tjenester er det viktig at man har med seg brukerne –- det vil si innbyggerne i Norge -– og lager ansvarlige systemer som gir lik og rettferdig behandling uavhengig av sosial status.</p>
</div>
<div id="beslutningsprosesser-rettferdighet-og-legitimitet" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Beslutningsprosesser, rettferdighet og legitimitet</h2>
<p>En massiv litteratur på prosedyrerettferdighet med utspring fra sosialpsykologi <span class="citation">(<a href="#ref-lind1988social" role="doc-biblioref">Lind and Tyler 1988</a>)</span> har hatt stor innvirkning på hvordan vi forstår relasjonene mellom innbyggere og myndighetene, og hvordan myndighetene bør forholde seg i møte med innbyggerne.
Når beslutningsprosessene dreier i retning av mer bruk av maskinlæring og kunstig intelligens, fungerer denne litteraturen som et velegnet rammeverk for å undersøke empirisk om, og i så fall hvordan, relasjonene mellom innbyggerne og myndighetene vil påvirkes av denne utviklingen.
Det vi vet fra eksperimentell forskning på politisk atferd er at både aspekter ved prosessen og utfallet i seg selv påvirker rettferdighetsoppfatningen av beslutningen og i sin tur villigheten til å akseptere beslutningen (se figur under).
På kort sikt handler det om å skaffe aksept for enkeltbeslutninger.
I et mer overordnet perspektiv dreier det seg om systemstøtte; om å sikre tillit og legitimitet til styresmaktene, og opprettholde tilfredsheten med demokratiet som styresett.
Legitimitet forstår vi her som makten til å få noen til villig å føye seg etter en beslutning <span class="citation">(<a href="#ref-weber2009theory" role="doc-biblioref">Weber 2009</a>)</span>, som i sin tur gir myndighetene den autoriteten de trenger for å styre effektivt uten bruk av sanksjoner <span class="citation">(<a href="#ref-tyler2021people" role="doc-biblioref">Tyler 2021</a>)</span>.
Demokratisk legitimitet viser til den legitimiteten som vinnes ved at beslutningene utgår fra folkeviljen <span class="citation">(<a href="#ref-rosanvallon2011democratic" role="doc-biblioref">Rosanvallon 2011</a>)</span>.
Både tillit og legitimitet omhandler relasjonen mellom innbyggere og myndighetene, og faller under det bredere konseptet om politisk støtte <span class="citation">(<a href="#ref-easton1965systems" role="doc-biblioref">Easton 1965</a>)</span>.</p>
<p>Prosessrelaterte spørsmål som har blitt studert er blant annet om rettferdighetsoppfatningen og aksepten av beslutningen påvirkes av forhold som er sentrale i demokratiske systemer.
Slike forhold kan for eksempel være grad av åpenhet rundt beslutningsprosessen <span class="citation">(<a href="#ref-de2014does" role="doc-biblioref">De Fine Licht et al. 2014</a>)</span>, mulighet for direkte påvirkning på en avgjørelse <span class="citation">(<a href="#ref-EJPR:EJPR2052" role="doc-biblioref">Esaiasson, Gilljam, and Persson 2012</a>; <a href="#ref-arnesen2017legitimacy" role="doc-biblioref">Arnesen 2017</a>; <a href="#ref-christensen2020matter" role="doc-biblioref">H. S. Christensen, Himmelroos, and Setälä 2020</a>)</span>, hvem beslutningstakerne er, og hvor godt disse beslutningstakerne gjenspeiler befolkningen med tanke på sosial bakgrunn <span class="citation">(<a href="#ref-arnesen2018legitimacy" role="doc-biblioref">Arnesen and Peters 2018</a>; <a href="#ref-clayton2019all" role="doc-biblioref">Clayton, O’Brien, and Piscopo 2019</a>)</span>.
Videre er et gjennomgående funn at dersom utfallet går imot ens egne ønsker, blir prosessen diskreditert <span class="citation">(<a href="#ref-esaiasson2016reconsidering" role="doc-biblioref">Esaiasson et al. 2016</a>)</span>.</p>
<p><img src="NAV_files/figure-html/dag-1.png" width="1440" /></p>
<p>Demokrati- og opinionsforskere har i liten grad studert hvordan overgangen til økt bruk av maskinlæring og kunstig intelligens i forvaltningens beslutningsprosesser kan påvirke systemtillit og legitimitet.
Unntak er De Fine Licht &amp; De Fine Licht <span class="citation">(<a href="#ref-de2020artificial" role="doc-biblioref">2020</a>)</span> som studerer rollen som åpenhet når det gjelder hvordan allmennheten oppfatter kunstig intelligens-beslutninger som legitim, og Binns et al <span class="citation">(<a href="#ref-binns2018s" role="doc-biblioref">2018</a>)</span> som foretar eksperimentelle studier som undersøker folks oppfatning av rettferdighet i algoritmiske beslutninger.
Vår kunnskap om hvordan overgangen vil påvirke innbyggernes oppfatninger av forvaltningen er imidlertid fortsatt begrenset, og behovet for befolkningsrepresentative studier med et demokratiperspektiv er stort.
Det er motivasjonen for å lage denne rapporten.</p>
<p>Rapporten presenterer resultatene fra en spørreundersøkelse gjennomført på et befolkningsrepresentativt utvalg av innbyggere i Norge.
Undersøkelsen tar for seg generelle holdninger til og kunnskap om maskinlæring og kunstig intelligens i befolkningen.
Bredere spørsmål knyttet til relasjonen mellom NAV og innbyggerne – uavhengig av tematikken om maskinlæring og kunstig intelligens – blir også analysert for å kontekstualisere de mer spesifikke spørsmålene og eksperimentene knyttet til bruk av maskinlæring og kunstig intelligens i NAV.
Deretter fokuserer vi på holdninger som har relevans for en framtid hvor maskinlæring og kunstig intelligens vil spille en sentral rolle.
Dette gjelder problemstillinger knyttet til konkrete, aktuelle situasjoner i NAV, såvel som mer overordnete spørsmål om maskinlæring og kunstig intelligens i forvaltningen.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-angwin2016machine" class="csl-entry">
Angwin, Julia, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. <span>“Machine Bias: There’s Software Used Across the Country to Predict Future Criminals. And It’s Biased Against Blacks.”</span> <em>ProPublica</em>. <a href="https://www.propublica.org/article/machine-bias-riskassessments-in-criminal-sentencing">https://www.propublica.org/article/machine-bias-riskassessments-in-criminal-sentencing</a>.
</div>
<div id="ref-arnesen2017legitimacy" class="csl-entry">
Arnesen, Sveinung. 2017. <span>“Legitimacy from Decision-Making Influence and Outcome Favourability: Results from General Population Survey Experiments.”</span> <em>Political Studies</em> 65 (1_suppl): 146–61.
</div>
<div id="ref-arnesen2018legitimacy" class="csl-entry">
Arnesen, Sveinung, and Yvette Peters. 2018. <span>“The Legitimacy of Representation: How Descriptive, Formal, and Responsiveness Representation Affect the Acceptability of Political Decisions.”</span> <em>Comparative Political Studies</em> 51 (7): 868–99.
</div>
<div id="ref-barocas2016big" class="csl-entry">
Barocas, Solon, and Andrew D Selbst. 2016. <span>“Big Data’s Disparate Impact.”</span>
</div>
<div id="ref-binns2018s" class="csl-entry">
Binns, Reuben, Max Van Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao, and Nigel Shadbolt. 2018. <span>“’It’s Reducing a Human Being to a Percentage’ Perceptions of Justice in Algorithmic Decisions.”</span> In <em>Proceedings of the 2018 Chi Conference on Human Factors in Computing Systems</em>, 1–14.
</div>
<div id="ref-christensen2020matter" class="csl-entry">
Christensen, Henrik Serup, Staffan Himmelroos, and Maija Setälä. 2020. <span>“A Matter of Life or Death: A Survey Experiment on the Perceived Legitimacy of Political Decision-Making on Euthanasia.”</span> <em>Parliamentary Affairs</em> 73 (3): 627–50.
</div>
<div id="ref-clayton2019all" class="csl-entry">
Clayton, Amanda, Diana Z O’Brien, and Jennifer M Piscopo. 2019. <span>“All Male Panels? Representation and Democratic Legitimacy.”</span> <em>American Journal of Political Science</em> 63 (1): 113–29.
</div>
<div id="ref-de2014does" class="csl-entry">
De Fine Licht, Jenny, Daniel Naurin, Peter Esaiasson, and Mikael Gilljam. 2014. <span>“When Does Transparency Generate Legitimacy? Experimenting on a Context-Bound Relationship.”</span> <em>Governance</em> 27 (1): 111–34.
</div>
<div id="ref-duwe2017effects" class="csl-entry">
Duwe, Grant, and Michael Rocque. 2017. <span>“Effects of Automating Recidivism Risk Assessment on Reliability, Predictive Validity, and Return on Investment (ROI).”</span> <em>Criminology &amp; Public Policy</em> 16 (1): 235–69.
</div>
<div id="ref-easton1965systems" class="csl-entry">
Easton, David. 1965. <span>“A Systems Analysis of Political Life.”</span>
</div>
<div id="ref-EJPR:EJPR2052" class="csl-entry">
Esaiasson, Peter, Mikael Gilljam, and Mikael Persson. 2012. <span>“Which Decision-Making Arrangements Generate the Strongest Legitimacy Beliefs? Evidence from a Randomised Field Experiment.”</span> <em>European Journal of Political Research</em> 51 (6): 785–808.
</div>
<div id="ref-esaiasson2016reconsidering" class="csl-entry">
Esaiasson, Peter, Mikael Persson, Mikael Gilljam, and Torun Lindholm. 2016. <span>“Reconsidering the Role of Procedures for Decision Acceptance.”</span> <em>British Journal of Political Science</em>, 1–24.
</div>
<div id="ref-de2020artificial" class="csl-entry">
Fine Licht, Karl de, and Jenny de Fine Licht. 2020. <span>“Artificial Intelligence, Transparency, and Public Decision-Making.”</span> <em>AI &amp; Society</em> 35 (4): 917–26.
</div>
<div id="ref-hansen2018digitalization" class="csl-entry">
Hansen, Hans-Tore, Kjetil Lundberg, and Liv Johanne Syltevik. 2018. <span>“Digitalization, Street-Level Bureaucracy and Welfare Users’ Experiences.”</span> <em>Social Policy &amp; Administration</em> 52 (1): 67–90.
</div>
<div id="ref-lind1988social" class="csl-entry">
Lind, E Allan, and Tom R Tyler. 1988. <em>The Social Psychology of Procedural Justice</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-pasquale2015black" class="csl-entry">
Pasquale, Frank. 2015. <em>The Black Box Society: The Secret Algorithms That Control Money and Information</em>. Harvard University Press.
</div>
<div id="ref-rosanvallon2011democratic" class="csl-entry">
Rosanvallon, Pierre. 2011. <em>Democratic Legitimacy</em>. Princeton University Press.
</div>
<div id="ref-tyler2021people" class="csl-entry">
———. 2021. <em>Why People Obey the Law</em>. Princeton university press.
</div>
<div id="ref-weber2009theory" class="csl-entry">
Weber, Max. 2009. <em>The Theory of Social and Economic Organization</em>. Simon; Schuster.
</div>
<div id="ref-zarsky2016trouble" class="csl-entry">
Zarsky, Tal. 2016. <span>“The Trouble with Algorithmic Decisions: An Analytic Road Map to Examine Efficiency and Fairness in Automated and Opaque Decision Making.”</span> <em>Science, Technology, &amp; Human Values</em> 41 (1): 118–32.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sammendrag.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="oppfatninger-om-nav.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["NAV.pdf", "NAV.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
