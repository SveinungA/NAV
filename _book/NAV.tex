% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\title{Demokratiske algoritmer}
\author{}
\date{\vspace{-2.5em}2022-03-01}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Demokratiske algoritmer},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{om}{%
\chapter{Om rapporten}\label{om}}

\hypertarget{forfattere}{%
\section{Forfattere}\label{forfattere}}

\textbf{Sveinung Arnesen} er Forsker I og faglig leder for Demokrati og innovasjon ved \href{https://www.norceresearch.no/personer/sveinung-arnesen}{NORCE}, og førsteamanuensis II ved \href{https://www.uib.no/personer/Sveinung.Arnesen}{Institutt for administrasjons- og organisasjonsvitenskap}, UiB.
PhD-graden ble avlagt ved \href{https://www.uib.no/sampol}{Institutt for sammenliknende politikk, UiB}.
Arnesen er Norges nasjonale koordinator for \href{europeansocialsurvey.org}{Den europeiske samfunnsundersøkelsen (ESS)}. \href{https://orcid.org/0000-0002-2825-0664}{ORCID}. \href{https://scholar.google.com/citations?user=xz8JwjAAAAAJ\&hl=no\&oi=ao}{Google Scholar}.

\textbf{Mikael P. Johannesson} er forsker ved NORCE, og PhD-kandidat ved Institutt for sammenliknende politikk, UiB.
Han har bred erfaring med eksperimentelle metoder, maskinlæring (inkludert deep learning), og surveyforskning.
Johannesson har utviklerkompetanse i statistikkprogrammet R, samt erfaring med Python (inkludert TensorFlow og Keras).

\hypertarget{referansegruppe}{%
\section{Referansegruppe}\label{referansegruppe}}

\textbf{Anne Lise Fimreite} er professor ved \href{https://www.uib.no/personer/Anne.Lise.Fimreite}{Institutt for administrasjons- og organisasjonsvitenskap}, UiB.
Hun har tidligere ledet den forskningsrådsfinansierte evaluering av NAV-reformen og har arbeidet mye med styringsutfordringer i flernivåsystem.
Hun har også nylig vært medlem av det offentlige utvalget som i 2019 leverte forslag til ny forvaltningslov (NOU 2019:5) og har egen erfaring fra offentlig forvaltning som prorektor ved UiB i fire år fra 2013 til 2017.

\textbf{Jacob Aars} er professor ved \href{https://www.uib.no/personer/Jacob.Aars}{Institutt for administrasjons- og organisasjonsvitenskap, UiB}, og har ledet den NFR-finansierte evalueringen av NAV-reformen (tok over da Fimreite gikk inn i rektoratet ved UiB).
Han har blant annet forsket på lokaldemokrati og tilfredshet med offentlige tjenester.

\hypertarget{data}{%
\section{Data}\label{data}}

Datagrunnlaget for denne rapporten er samlet inn i Norsk medborgerpanels runde 22 og 23.
Norsk medborgerpanel er en internettbasert undersøkelse om nordmenns holdninger til viktige samfunnstema.
Panelet drives av samfunnsforskere ved Universitetet i Bergen og NORCE, og er et non-profit prosjekt utelukkende benyttet til forskningsformål.
Deltakerne representerer et tverrsnitt av den norske befolkningen, som noen ganger i året inviteres til å si sin mening i viktige spørsmål om norsk samfunn og politikk.

Panelet blir driftet av \href{www.digsscore.uib.no}{Digital samfunnsvitenskapelig kjernefasilitet (DIGSSCORE)}.

Samlet antall respondenter som svarte på deler av denne undersøkelsen var 3971.
Typisk antall respondenter for hvert spørsmål er om lag 2000.

\href{https://www.uib.no/en/digsscore/122162/methodology-and-field-periods}{Metoderapport for data kan lastes ned her.}
Data er åpent tilgjengelig for forskere, og kan lastes ned ved å kontakte \href{https://sikt.no/}{Sikt -- Kunnskapssektorens tjenesteleverandør (tidligere kjent som NSD)}.

\hypertarget{finansiering}{%
\section{Finansiering}\label{finansiering}}

Forskningsrapporten er finansiert av \href{https://www.nav.no/no/nav-og-samfunn/kunnskap/fou-midler/pagaende-fou-prosjekter2/navs-tiltak-og-virkemidler}{NAV Forskning og Utvikling}.
Finansieringen er bidragsfinansiert.

\hypertarget{sammendrag}{%
\chapter{Utvidet sammendrag}\label{sammendrag}}

Den pågående automatiseringen av beslutningsprosesser i offentlig forvaltning representerer en omveltning innenfor byråkratisk myndighetsutøvelse.
Tilgang på store mengder relevant digital data og økende muligheter for å behandle informasjonen gjør at oppgaver som tidligere måtte behandles manuelt kan overlates til hel- eller halvautomatiserte prosesser med vesentlig redusert menneskelig inngripen.
På den ene siden gir denne utviklingen store effektiviseringsmuligheter og potensial for offentlige besparelser.
På den andre siden er ivaretakelsen av forvaltningens legitimitet i befolkningen et risikoaspekt i denne utviklingen.

NAV er ledende i utviklingen av digitale tjenester og verktøy, og utvikler systemer som kan nyttiggjøre seg framskritt som gjøres innenfor databehandling og analyse.
Beslutningsprosesser som benytter seg av kunstig intelligens vil være en del av løsningen for at NAV skal oppnå samfunnsoppdraget sitt om å bidra til at flere kommer i arbeid og færre på stønad, og samtidig sørge for at de som trenger det, får rett ytelse til rett tid gjennom en pålitelig og effektiv forvaltning.
Kunstig intelligens kan brukes både i automatiserte beslutningsprosesser, og som beslutningsstøtte for saksbehandlere.
Et sentralt kjennetegn ved kunstig intelligens er at slike systemer etterligner, erstatter og utvider menneskelig intelligent handling, og menneskelig beslutningstaking og vurdering.
Mulige områder hvor kunstig intelligens kan benyttes i NAV er blant annet for å beregne sannsynlighet for at den arbeidsledige trenger bistand fra NAV; til å bestemme om en person i sykefravær skal kalles inn til oppfølgingsmøte fra NAV; og til å anbefale arbeidsrettede tiltak.

På veien mot bedre tjenester er det viktig at man har med seg brukerne -- det vil si innbyggerne i Norge -- og lager ansvarlige systemer som gir lik og rettferdig behandling uavhengig av sosial status.
Det er viktig å studere rettferdighet fra et statsvitenskapelig perspektiv fordi oppfatninger av rettferdighet antas å påvirke institusjonell legitimitet.
Det overordnede målet med denne rapporten er derfor å belyse ut fra et demokratiperspektiv om, og i så fall hvordan, oppfattelsen av NAV som institusjon blant innbyggere i Norge påvirkes av en overgang til økt grad av automatisert saksbehandling.
Datagrunnlaget for denne rapporten er samlet inn i Norsk medborgerpanels i 2021, med et representativt utvalg av innbyggerne i Norge på 2000 respondenter.

For å kartlegge konteksten denne studien gjøres i, inkluderer undersøkelsen noen generelle spørsmål om innbyggernes forhold til NAV.
Vi finner at over halvparten av innbyggerne har vært i personlig kontakt med saksbehandler i NAV, men mange oppgir likevel at de har liten kjennskap til organisasjonen.
Flertallet av innbyggerne opplever at de er i stand til å få de tjenestene de har krav på fra det offentlige.
Dette på tross av at mange opplever forvaltningen som krevende å forstå.

Innbyggerne har rimelig høy tillit til NAV.
Tilliten er høyere blant de som opplever at de får ytelsene de har rett på; som føler at de forstår de byråkratiske prosessene; som tenker at de som jobber i offentlig sektor bryr seg om folks behov; og som oppfatter at saksbehandlerne ikke bare forholder seg til tekniske aspekter i saksbehandlingen.
Motsvarende er tilliten lavere blant de som har et annet syn på forvaltningen.

Den samme forskjellen observerer vi når spørsmålet dreier seg om hvorvidt saksbehandlerne oppfattes som upartiske i sin myndighetsutøvelse.
Innbyggerne mener i liten til noen grad at saksbehandlere i NAV lar seg påvirke av egne holdninger, men denne oppfattelsen varierer sterkt etter hvilken oppfatning de har om forvaltningen og tilliten de har til NAV.

Begrepet \emph{representativt byråkrati} springer ut fra tanken om at forvaltningen skal gjenspeile befolkningen og slik hindre at sosiale grupper i blir forskjellsbehandlet.
Eventuelle bias saksbehandlere måtte ha vil i så fall utjevnes ved at deres bakgrunn er variert og representativ for befolkningen samlet sett.
I vår studie finner vi økt støtte for representativt byråkrati når forvaltningen tar i maskinlæring og kunstig intelligens.
Innbyggerne blir mer opptatt av at saksbehandlerne deler deres sosiale bakgrunn når slike verktøy brukes i saksbehandlingen, og dette gjelder spesielt når det kommer til utdanningsnivå og arbeidserfaring.
Det trengs mer forskning for å forstå mekanismene som forklarer dette økte behovet, men en foreløpig hypotese er at bruk av maskinlæring og kunstig intelligens leder til økt fremmedgjøring, og at behovet øker for saksbehandlere som forstår den enkeltes situasjon og kan gripe inn i tilfeller hvor den maskinelle vurderingen ikke tar tilstrekkelig hensyn til kontekst.
Det er i alle fall klart at maskinlæring og kunstig intelligens er fremmed for et flertall av innbyggerne i Norge:
Mer enn seks av ti innbyggerne i Norge har liten eller ingen kjennskap til temaet.

Innbyggerne er delt i oppfatningen om bruken av maskinlæring og kunstig intelligens i forvaltningen er noe å bekymre seg over, og de som oppfatter at de har god kunnskap om tematikken er mer positive til at det brukes i forvaltningen.
Det er videre en omvendt U-formet sammenheng mellom selvplassering på politisk høyre/venstre-skala og oppslutning om bruk av kunstig intelligens:
Innbyggere som plasserer seg mot midten av det politiske spekteret er mer positive enn de som plasserer seg mot en av endene på skalaen.
Svarene må tolkes i sammenheng med at måten vi stilte spørsmålet fokuserer på konkrete avveininger av egenskaper ved ren manuell saksbehandling og saksbehandling med maskinlæring og kunstig intelligens.

Et viktig spørsmål knyttet til bruk av maskinlæring og kunstig intelligens er hvordan modellene kan ivareta oppfattelsen av at beslutninger som tas er rettferdige.
Det finnes imidlertid ulike definisjoner av hva rettferdighet er, og det er vanskelig -- for ikke å si umulig -- å oppfylle alle definisjonene på samme tid.
Vi har derfor i undersøkelsen tatt for oss et konkret tilfelle som er relevant for NAVs tjenester, hvor vi måler innbyggernes støtte til det som kalles \emph{statistisk paritet}.
Denne rettferdighetsdefinisjonen innebærer at man sikrer lik fordeling av et gode blant undergrupper i samfunnet, ofte basert på sosial eller etnisk tilhøriget.
Den konkrete saken gjelder bruk av maskinlæring og kunstig intelligens for å understøtte en beslutning om hvilke personer blant de sykmeldte som skal få tilbud om dialogmøte med NAV.
I vårt tilfelle har vi spurt hvilken modell man foretrekker av en som er mer treffsikker totalt sett, men skeivfordeler på kjønn, eller en som er mindre treffsikker totalt sett, men sikrer at like mange sykmeldte fra hvert kjønn får tilbud om dialogmøte.
Vi finner at befolkningen er delt omtrent på midten, med en liten overvekt av støtte til å bruke statistisk paritet.
Kvinner støtter statistisk paritet noe mer enn menn i dette konkrete tilfellet.
Både menn og kvinner støtter statistisk paritet i sterkere grad dersom det er kvinner som blir forfordelt, dog er denne effekten er sterkest blant kvinner.
Befolkningen er med andre ord ikke samstemt om hvilket rettferdighetskriterie som skal gjelde i dette tilfellet, noe som samsvarer med andre studier som viser at hva som er rettferdig er avhengig både av kontekst og av øyet som ser.

NOE OM INPUTVARIABLER HER

Mye forskning gjenstår for å kunne trekke vidtrekkende konklusjoner om hvordan tillit og legitimitet best kan bevares i overgangen til økt bruk av maskinlæring og kunstig intelligens.
Vi er fortsatt i en tidlig fase, hvor de fleste innbyggerne har liten kjennskap til tematikken, og hvor svært få har personlige erfaringer med saksbehandling hvor dette benyttes.
Problemstillingene kan være komplekse, og av og til kan det være vanskelig for den jevne innbygger å ta stilling til spørsmål som de ikke har tenkt mye over.
Samtidig er det nyttig å allerede nå merke seg at befolkningen er delte i mange av spørsmålene om maskinlæring og kunstig intelligens i forvaltningen, både når det gjelder bekymring for bruk og hva som er rettferdig framgangsmåte.
Innbyggerne er mer følsomme for spørsmål om bruk av maskinlæring og kunstig intelligens under omstendigheter hvor bruken knyttes opp mot sosiale bakgrunnsvariabler som ellers i samfunnet er politisk ladete.
Også internasjonalt ser vi at bruk av maskinlæring og kunstig intelligens når offentlighetens søkelys i de tilfellene hvor marginaliserte grupper opplever at de blir forskjellsbehandlet.

Spørsmålet om bruk av maskinlæring og kunstig intelligens er til syvende og sist et politisk spørsmål.
Det er viktig at dette taes hensyn til, og at modeller åpner for grundig politisk behandling før de settes ut i live.
Representasjon av interessegrupper, medvirkning i utformingen av modellene, og politisk ansvarliggjøring er demokratiske verktøy som virker i andre sammenhenger, og som det er grunn til å anta vil virke også i en overgang til automatisert forvaltning.

\hypertarget{bakgrunn}{%
\chapter{Bakgrunn og motivasjon}\label{bakgrunn}}

\hypertarget{byruxe5kratisk-omveltning}{%
\section{Byråkratisk omveltning}\label{byruxe5kratisk-omveltning}}

Den pågående automatiseringen av beslutningsprosesser i offentlig forvaltning representerer en omveltning innenfor byråkratisk myndighetsutøvelse.
Tilgang på store mengder relevant digital data og økende muligheter for å behandle informasjonen gjør at oppgaver som tidligere måtte behandles manuelt kan overlates til hel- eller halvautomatiserte prosesser med vesentlig redusert menneskelig inngripen \citep{zarsky2016trouble}.
På den ene siden gir denne utviklingen store effektiviseringsmuligheter og potensial for offentlige besparelser \citep{duwe2017effects}.
Den representerer også en mulighet for å utvikle bedre, evidensbaserte beslutninger, som i sin tur kan bidra til å bevare tilliten og legitimiteten til offentlig forvaltning.
På den andre siden er nettopp ivaretakelsen av forvaltningens legitimitet i befolkningen også et risikoaspekt i denne utviklingen.
En frykt er at feil bruk kan lede til utfall som negativt forskjellsbehandler svakerestilte grupper i samfunnet, som igjen underminerer systemtilliten.

En arbeidsgruppe oppnevnt av den tidligere amerikanske president Barack Obama publiserte rapporter hvor de uttrykte bekymring for ``kode-diskriminering» i automatiserte beslutninger, hvor diskriminering av sosiale grupper oppsto som en utilsiktet følge av måten stordatateknologi er strukturert og brukes.
Dystopiske skildringer av ``svart boks''-samfunn maler et skremmende bilde av et framtidssamfunn der innbyggernes skjebner blir bestemt av skjulte, upresise, og diskriminerende automatiske beslutningsprosesser \citep{barocas2016big, pasquale2015black}.
I de tilfeller oppmerksomheten når ut til allmennheten, har fokus tendert å handle om hvordan beslutningene slår ulikt ut sosiale grupper.
Det amerikanske nyhetsmagasinet ProPublica viste hvordan prediksjonsmodeller som brukes til å forutsi gjentakelsesfare for lovbrudd blant fengselsinnsatte systematisk kategoriserte svarte insatte oftere enn hvite feilaktig som personer med høy risiko for å begå en ny forbrytelse når de løslates fra fengselet (Angwin et al.~2016).

Opplevd diskriminering fra myndighetenes side mot sosiale grupperinger er ikke noe nytt, og spesielt ikke i USA hvor automatiserte beslutninger har fått mest oppmerksomhet til nå.
I Norge har vi mindre forskjeller mellom folk, både økonomisk, politisk og sosialt. Norge har også en høyt kompetent og effektiv offentlig forvaltning som jevnt over nyter høy tillit i befolkningen.
I overgangen til økt automatisering i forvaltningen er det viktig at tilliten og legitimiteten til offentlig forvaltning opprettholdes.

NAV er ledende i utviklingen av digitale tjenester og verktøy (Hansen, Lundberg, and Syltevik 2018), og utvikler systemer som kan nyttiggjøre seg framskritt som gjøres innenfor databehandling og analyse.
Beslutningsprosesser som benytter seg av kunstig intelligens vil være en del av løsningen for at NAV skal oppnå samfunnsoppdraget sitt om å bidra til at flere kommer i arbeid og færre på stønad, og samtidig sørge for at de som trenger det, får rett ytelse til rett tid gjennom en pålitelig og effektiv forvaltning.
Kunstig intelligens kan brukes både i automatiserte beslutningsprosesser, og som beslutningsstøtte for saksbehandlere.
Et sentralt kjennetegn ved kunstig intellignes er at slike systemer etterligner, erstatter og utvider menneskelig intelligent handling, og menneskelig beslutningstaking og vurdering (Mikkelsen 2019).
Mulige områder hvor kunstig intelligens kan benyttes i NAV er blant annet for å beregne sannsynlighet for at den arbeidsledige trenger bistand fra NAV; til å bestemme om en person i sykefravær skal kalles inn til oppfølgingsmøte fra NAV; og til å anbefale arbeidsrettede tiltak.
På veien mot bedre tjenester er det viktig at man har med seg brukerne -- det vil si innbyggerne i Norge -- og lager ansvarlige systemer som gir lik og rettferdig behandling uavhengig av sosial status.

\hypertarget{rettferdighet-og-legitimitet}{%
\section{Rettferdighet og legitimitet}\label{rettferdighet-og-legitimitet}}

En massiv litteratur på prosedyrerettferdighet med utspring fra sosialpsykologi (Tyler and Lind 1992) har hatt stor innvirkning på hvordan vi forstår relasjonene mellom innbyggere og myndighetene, og hvordan myndighetene bør forholde seg i møte med innbyggerne.
Når beslutningsprosessene dreier i retning av mer automatisering, fungerer denne litteraturen som et velegnet rammeverk for å undersøke empirisk om, og i så fall hvordan, relasjonene mellom innbyggerne og myndighetene vil påvirkes av denne utviklingen.
Det vi vet fra eksperimentell forskning på politisk atferd er at både aspekter ved prosessen og utfallet i seg selv påvirker rettferdighetsoppfatningen av beslutningen og i sin tur villigheten til å akseptere beslutningen (se figur under).
På kort sikt handler det om å skaffe aksept for enkeltbeslutninger.
I et mer overordnet perspektiv dreier det seg om systemstøtte; om å sikre tillit og legitimitet til styresmaktene, og opprettholde tilfredsheten med demokratiet som styresett.
Legitimitet forstår vi her som makten til å få noen til villig å føye seg etter en beslutning (Weber 2009), som i sin tur gir myndighetene den autoriteten de trenger for å styre effektivt uten bruk av sanksjoner (Tyler 2006).
Demokratisk legitimitet viser til den legitimiteten som vinnes ved at beslutningene utgår fra folkeviljen (Rosanvallon 2011).
Både tillit og legitimitet omhandler relasjonen mellom innbyggere og myndighetene, og faller under det bredere konseptet om politisk støtte (Easton 1965).

Prosessrelaterte spørsmål som har blitt studert er blant annet om rettferdighetsoppfatningen og aksepten av beslutningen påvirkes av forhold som er sentrale i demokratiske systemer.
Slike forhold kan for eksempel være grad av åpenhet rundt beslutningsprosessen (De Fine Licht et al.~2014), mulighet for direkte påvirkning på en avgjørelse (Esaiasson, Gilljam, and Persson 2012; Arnesen 2017; Christensen, Himmelroos, and Setälä 2020), hvem beslutningstakerne er, og hvor godt disse beslutningstakerne gjenspeiler befolkningen med tanke på sosial bakgrunn, også kjent som deskriptiv representasjon (Arnesen and Peters 2018; Clayton, O'Brien, and Piscopo 2019). Videre er et gjennomgående funn at dersom utfallet går imot ens egne ønsker, blir prosessen diskreditert (Esaiasson et al.~2019; Marien and Kern 2018; Arnesen, Broderstad, et al.~2019; Arnesen, Bergh, et al.~2019).

Det er viktig å studere rettferdighet fra et statsvitenskapelig perspektiv fordi oppfatninger av rettferdighet antas å påvirke institusjonell legitimitet (Tyler 2003). Dette begrenser seg ikke bare til input-siden av det politiske systemet hvor politikk vedtas, men også output-siden i forvaltningen hvor politikk settes ut i live (Krislov 2012; Rosanvallon 2011; Rothstein 2011).

\includegraphics{NAV_files/figure-latex/dag-1.pdf}

Forskningen på kunstig intelligens og rettferdighet er raskt voksende.
Flere definisjoner brukes om rettferdighet, og de fleste av dem er basert på forhold mellom sanne/falske positive og sanne/falske negativer (Verma and Rubin 2018).
Alexandra Chouldechova \citet{chouldechova2018case} viser teoretisk og empirisk hvordan to velbrukte definisjoner av rettferdighet umulig kan oppnås samtidig i visse tilfeller.
Hvilke definisjoner bør prioriteres når man står overfor slike avveininger?
Chouldechovas studie viser med tydelighet at det ikke er gjort i en håndvending å lage rettferdige prediksjonsmodeller.
Tvert imot er det komplisert utfordring som krever oppmerksomhet om konkret kontekst.
Vi vet fortsatt lite om hvilke definisjoner som resonnerer blant innbyggerne, og i hvilken grad de modereres av kontekst eller innbyggernes sosiale bakgrunn eller politiske holdninger.
Vi vet fra samfunnsforskning at hva som oppfattes som rettferdig kan variere med sosial identitet og kultur, politiske holdninger, og personlige karaktertrekk, og det er derfor viktig å gjøre konkrete empiriske studier på realistiske problemstillinger før slike prediksjonsmodeller tas i bruk.
I {[}kapittel{]} @ref(\#paritet) tar vi for oss et realistisk scenario for NAV hvor vi setter opp to motstridende rettferdighetshensyn knyttet til hvem som skal få tilbud om dialogmøte.

På tross av et økende krav om at innbyggerne må involveres og konsulteres (Balaram, Greenham, and Leonard 2018), har demokrati- og opinionsforskere i liten grad studert hvordan overgangen til økt bruk av kunstig intelligens i forvaltningen kan påvirke tillit og legitimitet.
Viktige unntak er De Fine Licht \& De Fine Licht (2020) som studerer rollen som åpenhet når det gjelder hvordan allmennheten oppfatter kunstig intelligens-beslutninger som legitim, og Binns et al (2018) som foretar eksperimentelle studier som undersøker folks oppfatning av rettferdighet i algoritmiske beslutninger.
Vår kunnskap om hvordan overgangen vil påvirke innbyggernes oppfatninger av forvaltningen er imidlertid fortsatt svært begrenset, og behovet for befolkningsrepresentative studier med et demokratiperspektiv er stort.
Det er motivasjonen for å lage denne rapporten.

Rapporten presenterer resultatene fra en spørreundersøkelse gjennomført på et befolkningsrepresentativt utvalg av innbyggere i Norge.
Undersøkelsen tar for seg generelle holdninger til og kunnskap om maskinlæring og kunstig intelligens i befolkningen.
Bredere spørsmål knyttet til relasjonen mellom NAV og innbyggerne -- uavhengig av tematikken om maskinlæring og kunstig intelligens -- blir også analysert for å kontekstualisere de mer spesifikke spørsmålene og eksperimentene knyttet til bruk av maskinlæring og kunstig intelligens i NAV.
Deretter fokuserer vi på holdninger som har relevans for en framtid hvor maskinlæring og kunstig intelligens har en sentral rolle i.
Dette gjelder problemstillinger knyttet til konkrete, aktuelle situasjoner i NAV, såvel som mer overordnete spørsmål om maskinlæring og kunstig intelligens i forvaltningen.

\hypertarget{oppfatninger-om-nav}{%
\chapter{Oppfatninger om NAV}\label{oppfatninger-om-nav}}

I dette kapitlet ser vi nærmere på relasjonen mellom NAV og innbyggerne i Norge.
Kapitlet danner grunnlaget for å forstå konteksten når vi senere fokuserer mer spesifikt på maskinlæring og kunstig intelligens i organisasjone.
Vi måler folks tillit til NAV, samt deres erfaring med og kjennskap til NAV.
Vi måler også i hvilken grad innbyggerne opplever at de forstår hvordan organisasjonen fungerer, og i hvilken grad de opplever at deres interesser blir ivaretatt i systemet.

Vi finner at

\begin{itemize}
\item
  over halvparten av innbyggerne har vært i personlig kontakt med saksbehandler i NAV, men mange oppgir likevel at de har liten kjennskap til NAV.
\item
  innbyggerne har middels til høy tillit til NAV. Det er få som oppgir å ha svært høy tillit eller ingen tillit i det hele tatt.
\item
  flertallet av innbyggerne opplever at de er i stand til å få de tjenestene de har krav på fra det offentlige. Dette på tross av at mange opplever forvaltningen som krevende å forstå.
\item
  innbyggerne i liten til noen grad mener at saksbehandlere i NAV lar seg påvirke av egne holdninger. Det skiller lite mellom hvilke områder av NAVs ansvarsområde man spør etter.
\end{itemize}

\hypertarget{erfaring-med-og-kjennskap-til-nav}{%
\section{Erfaring med og kjennskap til NAV}\label{erfaring-med-og-kjennskap-til-nav}}

Et flertall av innbyggerne i Norge har hatt befatning med NAV i en eller annen form.
Noen kontakter er lite personlige, som for eksempel når man mottar barnetrygd.
Andre krever mer kontakt med NAV, og gjerne personlig kontakt med en saksbehandler.
I vårt utvalg har godt over halvparten minst en gang vært i personlig kontakt med NAV.

\begin{figure}
\centering
\includegraphics{figs/png/fig_nav_personal_contact.png}
\caption{Personlig kontakt med NAV}
\end{figure}

Fire av ti innbyggere i Norge har liten eller ingen kjennskap til NAV, mens seks av ti har ganske god, god, eller svært god kjennskapt til institusjonen.

\includegraphics{figs/png/fig_nav_knowledge.png}

\hypertarget{tillit}{%
\section{Tillit}\label{tillit}}

Norge er kjent som et land der myndighetene nyter høy tillit i befolkningen.
Dette bekreftes også i vår undersøkelse for NAV sin del.
Fire av ti innbyggere i Norge har høy eller svært høy tillit til NAV, mens bare en av seks har liten eller ingen tillit.
På en skala fra 1 til 5 der 1 er lavest og 5 er høyest, er gjennomsnittsverdien på \textbf{xx}.

\begin{figure}
\centering
\includegraphics{figs/png/fig_nav_trust.png}
\caption{Tillit til NAV}
\end{figure}

Tillit er noe som tar lang til å bygge opp, men som fort kan rives ned.
Det er et godt utgangspunkt at NAV nyter tillit i befolkningen, og ikke desto viktigere at denne relasjonen ivaretaes parallelt med at organisasjonen endrer seg og utvikler morgendagens forvaltning.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  SAMMENLIKNE MED TILLIT TIL ANDRE ORGANISASJONER
\item
  TILLIT BRUTT NED PÅ ERFARING MED OG KJENNSKAP TIL NAV
\end{enumerate}

\hypertarget{byruxe5kratisk-kompetanse}{%
\section{Byråkratisk kompetanse}\label{byruxe5kratisk-kompetanse}}

I statsvitenskapen opererer man med et begrep som på engelsk heter \emph{political efficacy}.
Vi kan gjerne oversette begrepet på norsk til \emph{politisk kompetanse}.
Politisk kompetanse viser til en persons selvopplevde evne til å forstå politikk (\emph{internal political efficacy}), og personens opplevelse av å kunne påvirke politiske prosesser (\emph{external political efficacy}).
Vi ser at intern og ekstern politisk kompetanse henger sammen med politisk deltakelse, med tilfredshet med demokratiet, tillit til institusjoner, blant annet.

På samme måte som at innbyggerne har ulike evner til å forstå politikk og påvirke politiske prosesser, har de også ulike evner til å forstå forvaltningen.
I motsetning til i politisk arbeid er det ikke et mål at innbyggerne nødvendigvis skal kunne påvirke en byråkratisk prosess, men det er likefullt en kjennsgjerning at noen personer er flinkere til å følge opp saker på vegne av seg selv eller pårørende, og slik sett er bedre i stand til å ivareta sine interesser i saker som angår dem.

For å avdekke hvordan disse ferdighetene fordeler seg i befolkningen har vi spurt respondentene om deres byråkratiske kompetanse - intern og ekstern.
Intern byråkratisk kompetanse måler vi ved hjelp av to påstander som de skal si seg enig eller uenig i:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Jeg er i stand til å skaffe alle offentlige ytelser, tjenester, og tillatelser som jeg har rett på.
\item
  Den offentlige forvaltningen er så innviklet at folk som meg ikke kan forstå hva som foregår innad i ulike etater, direktorat, kommuner, og så videre.
\end{enumerate}

Ekstern byråkratisk kompetanse måler vi ved hjelp av to nye påstander:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  De som jobber i den offentlige forvaltningen bryr seg ikke om hvilke behov folk som meg har.
\item
  Saksbehandlere i den offentlige forvaltningen er bare interessert i tekniske aspekter ved saken, ikke hva de det berører faktisk ønsker.
\end{enumerate}

\includegraphics{figs/png/fig_be_hist.png}

Figurene viser at det er ganske stor spredning i svarene.
Flertallet av innbyggerne er enige i påstanden at de får alle ytelser som de har rett på.
Et flertall svarer samtidig at de opplever byråkratiet som vanskelig å forstå.
Flertallet er uenige i at de som jobber i offentlig forvaltning ikke bryr seg om folks behov, men det er også et stort mindretall som er enige i denne påstanden.
Et lite flertall mener at saksbehandlere bare er interessert i tekniske aspekter ved saken.

Dette er befolkningen i sin helhet.
Når vi bryter svarene ned på sosiopolitiske undergrupper ser vi at dem som har lav byråkratisk kompetanse også har lav politisk kompetanse (efficacy).
Det vil si at de som har tillit til NAV er de som opplever at de får ytelsene de har rett på, som føler at de forstår de byråkratiske prosessene, som tenker at de som jobber i offentlig sektor bryr seg om folks behov, og som ikke bare forholder seg til tekniske aspekter i saksbehandlingen.

\includegraphics{figs/png/fig_be_coefs_by_type.png}

Byråkratisk kompetanse varierer også til dels mye mellom folk når vi deler dem inn i hvilket parti de ville ha stemt på dersom det var stortingsvalg i morgen.
Figuren under viser at det er størst forskjell på de som stemmer Fremskrittspartiet og de som stemmer Miljøpartiet de grønne, spesielt når det gjelder ekstern byråkratisk kompetanse.

Menn scorer noe lavere enn kvinner på ekstern byråkratisk kompetanse, og det samme gjør personer uten høyere utdanning sammenliknet med personer med høyere utdanning.
De scorer også noe lavere på intern byråkratisk kompetanse, men her er forskjellen mindre (men fortsatt statistisk signifikant).

Tillit til NAV samvarierer også sterkt med byråkratisk kompetanse.
Figuren under viser mer dette mer detaljert.
Vi observerer en lineær sammenheng mellom de to variablene, som flater ut først blant de som har svært høy tillit til NAV.
\includegraphics{figs/png/fig_be_by_navtrust.png}

\hypertarget{tiltro-til-likebehandling-i-nav}{%
\section{Tiltro til likebehandling i NAV}\label{tiltro-til-likebehandling-i-nav}}

Et styrende prinsipp i norsk forvaltning er nøytralitet:
Saksbehandlere skal utøve sitt mandat uten å la egne holdninger komme i veien og påvirke beslutningsprosessen.
Slik uhildet behandling av innbyggerne står også sentralt i forskning på hvilke egenskaper ved byråkratiet som underbygger legitimitet og rettferdighetsoppfatninger.
Når vi spør innbyggerne i Norge hvordan de oppfatter at saksbehandlerne i NAV lar seg påvirke av egne holdninger, finner vi at de tror det forekommer i noen grad.
Det er liten forskjell på de ulike områdene innenfor NAV.

\includegraphics{figs/png/fig_nav_exp_attinfluence_all.png}
\includegraphics{figs/png/fig_nav_exp_attinfluence_area.png}
Figuren under viser også at byråkratisk kompetanse (omtalt i forrige kapittel) samvarierer med oppfatningen om at saksbehandlere lar seg påvirke av egne holdninger:
Jo høyere byråkratisk kompetanse en innbygger har, desto mindre mener man at saksbehandlerne lar seg påvirke av egne holdninger.

\includegraphics{figs/png/fig_attinfluence_by_be.png}
I utvalget mener de som har vært i personlig kontakt med en saksbehandler i NAV i litt større grad at saksbehandlerne lar seg påvirke av egne holdninger.
Forskjellen er imidlertid ikke stor, og HELLER IKKE STATISTISK SIGNIFIKANT.
\includegraphics{figs/png/fig_attinfluence_by_contact.png}

\hypertarget{kunstig-intelligens-i-forvaltningen}{%
\chapter{Kunstig intelligens i forvaltningen}\label{kunstig-intelligens-i-forvaltningen}}

\begin{itemize}
\item
  Mer enn seks av ti innbyggerne i Norge har liten eller ingen kjennskap til maskinlæring og kunstig intelligens
\item
  Innbyggerne er delt i oppfatningen om bruken av maskinlæring og kunstig intelligens i forvaltningen er noe å bekymre seg over
\item
  De som oppfatter at de har god kunnskap om maskinlæring er mer positive til bruk av kunstig intelligens i forvaltningen
\item
  Det er en omvendt U-formet sammenheng mellom selvplassering på politisk høyre/venstre-skala og oppslutning om bruk av kunstig intelligens:
  Innbyggere som plasserer seg mot midten av det politiske spekteret er mer positive enn de som plasserer seg mot en av endene på skalaen.
\end{itemize}

\hypertarget{norske-innbyggeres-kjennskap-og-fuxf8lelser-knyttet-til-maskinluxe6ring-og-kunstig-intelligens}{%
\section{Norske innbyggeres kjennskap og følelser knyttet til maskinlæring og kunstig intelligens}\label{norske-innbyggeres-kjennskap-og-fuxf8lelser-knyttet-til-maskinluxe6ring-og-kunstig-intelligens}}

Maskinlæring som databehandlingsmetode er relativt fersk.
Med økt datakraft og økt tilgang på data, har bruk av maskinlæring bredt om seg innenfor datavitenskapelige miljøer.
I befolkningen for øvrig er det lite kjennskap til maskinlæring og kunstig intelligens.
Bare en av syv innbyggere oppgir at de har god eller svært god kjennskap til maskinlæring og kunstig intelligens, mens nesten to tredjeler sier at de har liten eller ingen kjennskap til det i det hele tatt.

\includegraphics{figs/png/fig_ml_knowledge.png}

Innbyggerne er delt i synet på grad av bekymring knyttet til bruk av maskinlæring og kunstig intelligens i den offentlige forvaltningen.

\begin{figure}
\centering
\includegraphics{figs/png/fig_ml_worried.png}
\caption{Bekymring for maskinlæring}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  ÅPENT TEKSTSVAR MED BEGRUNNELSE FOR SVAR OM BEKYMRING
\item
  ER DET MANGEL PÅ KUNNSKAP SOM LEDER TIL BEKYMRING?
\end{enumerate}

\hypertarget{interesser-ivaretatt-med-maskinluxe6ring}{%
\subsection{Interesser ivaretatt med maskinlæring?}\label{interesser-ivaretatt-med-maskinluxe6ring}}

Det er naturlig å se maskinlæring og kunstig intelligens i NAV i sammenheng med spørsmål som ligger nær opptil byråkratisk kompetanse.
Vil folk oppleve at det er lettere eller vanskeligere å forstå hvordan byråkratiet fungerer?
Vil deres interesser ivaretas bedre eller dårligere når maskinlæring brukes i NAV?

\begin{figure}
\centering
\includegraphics{figs/png/fig_nav_ml_helps_interest.png}
\caption{Maskinlæring i NAV}
\end{figure}

Det mest vanlige svaret var midtkategorien `verken bedre eller dårligere'.
For øvrig fordelte svarene seg normalt rundt denne midtkategorien.
I spørreundersøkelser kan midtkategorier i slike bipolare skalaer (les: bedre vs.~dårligere) ofte skjule at respondentene ikke har noen mening om spørsmålet.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  VI DELER DERFOR OPP SVARENE SLIK AT VI KAN UNDERSØKE OM SVARENE TIL RESPONDENTENE VARIERER ETTER HVOR GOD KJENNSKAP DE HAR TIL MASKINLÆRING.
\end{enumerate}

\hypertarget{bruke-kunstig-intelligens}{%
\section{Bruke kunstig intelligens?}\label{bruke-kunstig-intelligens}}

I mange beslutninger i forvaltningen må det utvises skjønn basert på en samlet vurdering av den enkelte saken.
Om man tar i bruk kunstig intelligens, ved hjelp av maskinlæring, vil beslutningene antakelig bli mer treffsikker, og dermed øke andelen riktige beslutninger.
Samtidig kan heller ikke en datamaskin være helt treffsikker.
Det er også grunn til å tro at den gjenværende andelen uriktige beslutninger går mer systematisk ut over noen grupper i samfunnet når man bruker maskinlæring og kunstig intelligens.
Dette fordi det er stor variasjon mellom hvordan menneskelige saksbehandlere utviser skjønn, mens for en datamaskin er det ingen variasjon.

Med dette som bakgrunn spurte vi respondentene hva foretrekker i slike situasjoner:
Enten

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Bruke kunstig intelligens, som fører til mange flere riktige beslutninger i bytte mot at det alltid er de samme som blir gjenstand for uriktige avgjørelser, eller
\item
  ikke bruke kunstig intelligens, som fører til mange færre riktige beslutninger i bytte mot at det varierer hvem som blir gjenstand for uriktige avgjørelser.
\end{enumerate}

Respondentene delte seg på midten i dette spørsmålet, hvor XX PROSENT FORETRAKK Å BRUKE KUNSTIG INTELLIGENS, MENS XX FORETRAKK Å IKKE BRUKE KUNSTIG INTELLIGENS.
Figuren under viser at de med lav kjennskap til maskinlæring og kunstig intelligens var mest skeptiske.
Det kan altså ha sammenheng med skepsis til det ukjente.

\includegraphics[width=0.7\textwidth,height=\textheight]{figs/png/fig_relval_ml_know.png}

Spørsmålet har også en politisk-filosofisk dimensjon over seg.
Premisset som legges til grunn for spørsmålet er at man ved å innføre kunstig intelligens påvirker fordelingen av riktige beslutninger.
(Man kan selvsagt diskutere om dette er en riktig virkelighetsbeskrivelse av en forvaltning som bruker kunstig intelligens versus en som ikke gjør det.
Vi kommer i denne omgang ikke nærmere inn på dette.)
Det blir da et spørsmål om fordeling av goder, og om man er villig til å ofre et lite antall individer som systematisk forfordeles med uriktige beslutninger, mot at populasjonen som helhet nyter godt av en høyere andel riktige beslutninger.

Ut fra dette perspektivet gir det mening at de som plasserer seg lengst til venstre er minst villige til å bruke kunstig intelligens.
Vi noterer oss også at de som plasserer seg lengst til høyre også er mindre villige til å bruke kunstig intelligens når konsekvensene av bruken presenteres slik som den har blitt gjort i dette konkrete tilfellet.

\includegraphics[width=0.7\textwidth,height=\textheight]{figs/png/fig_relval_polscale.png}

Det er viktig å ha i mente at de to siste kulepunktene omhandler svar som blir gitt i en spesifikk ``framing'' av kunstig intelligens; nemlig en situasjon hvor bruken av kunstig intelligens påvirker beslutningene på en måte som gjør dem mer treffsikre, men samtidig mer systematisk feildiagnostiserer.

Når vi fokuserte spesifikt på en endring av hvordan beslutninger fattes ved bruk av kunstig intelligens kontra uten.

\hypertarget{paritet}{%
\chapter{Statistisk paritet}\label{paritet}}

Et realistisk eksempel hvor maskinlæring kan brukes i forvaltningen er når NAV skal bestemme hvilke sykmeldte som skal få tilbud om dialogmøte med NAV.
Et dialogmøte er en samtale mellom NAV og den sykmeldte som anses som positivt for den sykmeldtes muligheter for å komme tilbake i arbeid.

I prinsippet har alle rett på et dialogmøte, men i praksis foregår det en siling hvor det gjøres en vurdering av hvem som har mest nytte av et slikt møte.
Bruk av maskinlæring og kunstig intelligens kan i dette tilfellet bidra til bedre estimater for hvem som er i fare for å bli langtidssykemeldt, og derfor kan ha større nytte av et dialogmøte.
Derfor er NAV i innledende stadier på å utvikle maskinlæringsmodeller som predikerer sannsynlighet for at en sykemeldt fortsatt vil være sykemeldt 12 uker fram i tid.

Når man bestemmer innretningen på en modell må man foreta prioriteringer.
En prinsipielt viktig prioritering handler om man skal ta i bruk såkalt statistisk paritet som rettferdighetsprinsipp på utvalgte egenskaper ved individene det gjelder.
Kjønnsparitet er ett eksempel, men det kan også handle om statistisk paritet etter alder, etnisitet, geografi, med mer.
Et kjent eksempel innenfor litteraturen om rettferdig bruk av kunstig intelligens er studien som viser hvordan afro-amerikanske fengselsinnsatte sjeldnere blir tilbudt prøveløslatelse enn hva andelen deres skulle tilsi.
Dette skjer når avgjørelsen om prøveløslatelse baserer seg på prediksjonsmodeller om risikoen for at den innsatte blir tatt påny for en kriminell handling dersom hen slippes fri (Chouldechova 2017).
Å anvende paritetsprinsippet her innebærer å sikre at andelen innsatte som tilbys prøveløslatelse samsvarer med andelen innsatte for hver av de etniske gruppene i fengselet.
Fordelen med å bruke statistisk paritet etter etnisitet er at prøveløslatelse blir likt fordelt blant de etniske gruppene, og slik sett kan oppleves som rettferdig fordelt.
Utfordringen ved å bruke dette prinsippet er at andre egenskaper ved de innsatte -- som for eksempel risikovurderinger om tilbakefall til kriminelle handlinger -- blir nedprioritert.
Er etnisitet i dette tilfellet så viktig at man bør la det gå på bekostning av risikovurderinger knyttet til tilbakefall?

NAVs tilfelle om dialogmøte er mindre dramatisk enn eksempelet om prøveløslatelse.
Samtidig er de prinsipielle problemstillingene de samme.
Statistisk paritet innebærer i tilfellet om dialogmøte at modellen sikrer at like mange menn og kvinner skal få tilbud om dialogmøte.
Denne prioriteringer vil i så fall gå delvis på bekostning av å prioritere treffsikkerhet med tanke på å invitere de som har størst nytte av et slikt møte.

For å studere respondentenes umiddelbare reaksjoner til et slik etisk dilemma knyttet til rettferdig bruk av kunstig intelligens ber vi respondentene se for seg et valg mellom to alternative maskinlæringsmodeller for å velge hvem som skal få tilbud om dialogmøte.

Ingen av modellene er perfekte, men de feiler på ulike måter.

Den første modellen er mest \emph{treffsikker}.
Det vil si at det totalt sett er flere sykemeldte med behov for dialogmøte som får tilbudet enn tilfellet er for den andre modellen.
Samtidig har modellen en bias til fordel for menn, som gjør at det er flere kvinner med behov for dialogmøte som ikke får tilbudet.
Andelen som har behov for dialogmøte \emph{uten å få tilbud} er altså større hos kvinner enn menn.

Den andre modellen sikrer statistisk paritet etter kjønn, nemlig at andelen av de sykmeldte som kalles inn til dialogmøte er like stor henholdsvis for kvinner som for menn.
Imidlertid er den mindre treffsikker totalt sett, slik at færre som har behov for dialogmøte blir innkalt.
Dette gjelder både kvinner og menn.

Hvis det står mellom disse to modellene, hvilken modell synes respondentene virker mest rettferdig?
Figuren under viser at et knapt flertall foretrekker en modell som vektlegger statistisk paritet.
Det vil si at de ønsker å bruke en modell som sikrer likebehandling av kjønn, selv på bekostning av lavere treffsikkerhet totalt sett.

\includegraphics{figs/png/fig_parity_avg.png}

I teksten over står det at den mest treffsikre modellen favoriserte menn.
For å undersøke om det har noen innvirkning på svarene hvilket kjønn modellen favoriserer veksler vi på denne beskrivelsen.
Halvparen av respondentene får vite at modellen har en bias til fordel for menn, mens den andre halvparten av respondentene får vite at modellen favoriserer kvinner.
Spiller det noen rolle hvilket kjønn modellen favoriserer?
Resultatene viser at det gjør det.

I figuren under ser vi at det er i de tilfeller hvor menn blir fordelaktig behandlet ved bruk av den mest treffsikre modellen at flertallet ønsker å bruke en modell som sikrer likebehandling av kjønn.
Det er en signifikant større andel av respondentene som foretrekker paritetsprinsippet når menn har fordel av den treffsikre modellen enn når kvinner har det.

Hva dette skyldes vet vi ikke.
Man ser liknende kjønnseffekter i eksperimenter om politisk representasjon, hvor kvinnelige kandidater jevnt over foretrekkes i noe høyere grad enn mannlige kandidater gjør (Schwarz \& Coppock 2020).
I den litteraturen pekes det på forklaringer om at folk er motivert ut fra et ønske om å kompensere for historisk underrepresentasjon av kvinner i politiske stillinger.
Hvorvidt det ligger liknende strukturelle motivasjoner for våre resultater, psykologiske faktorer, eller andre forhold er et interessant forskningsspørsmål som vi ikke har data til å besvare, og som derfor bør studeres videre.

\includegraphics{figs/png/fig_parity_treat_avg.png}

Det vi imidlertid ser, og til forskjell fra litteraturen om politisk representasjon, er at kvinner responderer noe mer på informasjon om hvilket kjønn som kommer best ut av en modell som prioriterer treffsikkerhet.
Både menn og kvinner foretrekker paritetsmodellen oftere i de tilfellene kvinnene kommer dårlig ut av treffsikkerhetsmodellen enn i de tilfellene hvor menn kommer dårlig ut av samme modell, men denne effekten er noe sterkere hos kvinner enn menn.

Det er også en generell forskjell blant respondentene i den forstand at kvinner i sterkere grad foretrekker paritetsmodellen enn menn gjør, uavhengig av om det er menn eller kvinner som kommer best ut av det.

\includegraphics{figs/png/fig_parity_treat_avg_by_gender.png}
Vi observerer også en modererende effekt av kunnskap om maskinlæring:
Jevnt over ser vi at jo høyere kunnskap om maskinlæring, desto høyere andel modellen som prioriterer treffsikkerhet framfor statistisk paritet.
Det her er igjen verdt å nevne at slike bivariate, statistiske sammehenger ikke sier noe om årsakssammenhenger.
SKAL VI TA MED DENNE FIGUREN? DEN PASSER IKKE SUPERGODT INN I NARRATIVET, OG ER VANSKELIG Å DISKUTERE.
\includegraphics{figs/png/fig_parity_treat_avg_by_ml_know.png}

\hypertarget{input}{%
\chapter{Inputvariabler}\label{input}}

\includegraphics{figs/png/fig_vars_avg.png}
\includegraphics{figs/png/fig_vars_hist.png}

\includegraphics{figs/png/fig_vars_avg_utd.png}

\includegraphics{figs/png/fig_vars_avg_ml_know.png}

\hypertarget{representasjon}{%
\chapter{Representativt byråkrati}\label{representasjon}}

Deskriptiv representasjon er et viktig konsept innenfor studiet av politisk representasjon (Pitkin 1967).
Velgere ønsker å bli representert av kandidater som deler deres sosiale bakgrunn, ikke minst fordi de antar at disse kandidatene deler deres politiske interesser og vil ivareta dem på en god måte (Arnesen, Duell, Johannesson 2019).

Mens spørsmål om representasjon er en naturlig del av studier knyttet til input-siden av det politiske systemet (Easton xxxx), er det mindre brukt for å studere output-siden, altså i forvaltningen, hvor politikk skal gjennomføres.
Grunnen til dette er tanken om at det er tilstrekkelig med demokratisk innflytelse i utformingen av politikken, så lenge forvaltningen utfører den vedtatte politikken på en upartisk måte (Rothstein 2011, Rosanvallon 2011).
Denne weberianske forestillingen om et byråkrati som ikke skal ha noen selvstendig innflytelse på politikken har vært hovedskildringen av hvordan den norske politisk-administrative systemet skal være og er.

Samtidig er forskning innen psykologi tydelig på at alle mennesker har systematiske bias som i større eller mindre grad former deres holdninger og atferd.
Det er ikke realistisk å anta at saksbehandlere fullt og helt klarer å legge fra seg egne bias i sitt arbeid, selv ikke i profesjoner hvor objektivitet etterstrebes.
En måte å utlikne bias er å sørge for at saksbehandlernes bakgrunn reflekterer befolkningen.
I det representative byråkratiet skal forvaltningsstaben utgjøre et tverrsnitt av det folket den skal tjene (Lægreid og Olsen 1978; Christensen, Lægreid og Zuna 2001).
Utgangspunktet er at den sosiale bakgrunnen til den enkelte tjenestemannen har gjennomslagskraft overfor hens tenkemåte og handlemåte.

Vi har tidligere sett at mange innbyggere tror at saksbehandlere i NAV lar seg påvirke i noen grad av egne holdninger.
Med dette som bakteppe er det grunn til å anta at innbyggerne ønsker at saksbehandlerne deler erfaringsbakgrunn med dem selv, slik at de forstår deres situasjon kanskje bedre enn en saksbehandler som har en helt annen bakgrunn.

Vi undersøker dette med utgangspunkt i en et design hentet fra en studie om deskriptiv representasjon i politiske beslutningsprosesser.
Hvilke egenskaper -- om noen -- ønsker innbyggerne at saksbehandlerne deler med dem?
Figuren under viser at deskriptiv representasjon generelt er lite viktig for innbyggerne.
Minst viktig er seksuell legning, mens arbeidserfaring og utdanningsnivå troner øverst.

Med vårt fokus på maskinlæring og kunstig intelligens ønsker vi å vite om behovet for deskriptiv representasjon i byråkratiet påvirkes når forvaltningen i tar i bruk dette verktøyet.
Det er ikke åpenbart på forhånd hvordan denne utviklkningen vil slå ut.
På den ene siden kan behovet for at saksbehandlerne deler ens sosiale bakgrunn bli mindre viktig, ettersom alle beslutninger blir mer strømlinjeformede og dermed mindre påvirket av saksbehandlernes bakgrunn.

På den andre siden kan innbyggerne oppleve at man med denne strømlinjeformingen går glipp av viktige nyanser i hver enkelt avgjørelse, og at det er nettopp i slike situasjoner at man er avhengive av saksbehandlere som har forståelse for innbyggernes situasjon og kan gå inn og korrigere i enkelttilfeller.

Resultatene fra eksperimentet viser at folk jevnt over blir mer opptatt av deskriptiv representasjon når forvaltningen benytter seg av maskinlæring og kunstig intelligens som beslutningsstøtte.
Vi velger å tolke dette som at kunstig intelligens fører til ytterligere fremmedgjøring av beslutningsprosesser i forvaltningen, som igjen presser fram et følt behov for å ha noen beslutningstakere som kjenner deres situasjon og kan ivarete deres rettigheter og interesser i denne prosessen.

\includegraphics{figs/png/fig_exp_repr_each.png}

Som det framgår av figuren under er endringene i retning av at deskriptiv representasjon blir viktigere med innføring av maskinlæring likevel små.
Deskriptiv representasjon i forvaltninge er lite viktig for folk flest, og blir bare litt viktigere ved innføring av maskinlæring og kunstig intelligens.

\includegraphics{figs/png/fig_exp_repr_avg.png}

  \bibliography{book.bib,packages.bib}

\end{document}
